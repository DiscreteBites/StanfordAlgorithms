{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Tables\n",
    "\n",
    "The goal is to maintain a (possibly evolving) set of objects. We aim to implement insert, delete and lookup (via a key). Using a properly implemented hash table, all of these operations can be done in $O(1)$ time (for \"non-pathalogical\" data)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $U$ be the universe of all possible elements. We aim to maintain a evolving set $S \\subseteq U$.\n",
    "\n",
    "1. Pick $n = O(\\lvert S \\rvert)$, \n",
    "2. choose a hash function\n",
    "$$\n",
    "h: U \\mapsto \\{0, 1, 2, \\cdots, n-1 \\}\n",
    "$$\n",
    "3. use an array $A$ of length $n$ store $x$ in $A[h(x)]$\n",
    "\n",
    "In general however, with only $\\sqrt{n}$ elements, there is a $50%$ chance of two elements mapping to the same hash. To resolve collisions we may opt to\n",
    "\n",
    "1. Seperate chaining: \n",
    "\n",
    "    Create a linked link in each bucket\n",
    "2. Open addressing:\n",
    "\n",
    "    maintain only one object per bucket. Using a hash function to specify a sequence of arrays to try, until we find an open slot.\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good hash function achieves two things\n",
    "1. Spreads out the data evenly\n",
    "2. Easy to compute / remeber the hash\n",
    "\n",
    "The load of a hash table is\n",
    "$$\n",
    "\\alpha = \\frac{\\text{\\# objects in hash table}}{\\text{\\# of buckets}}\n",
    "$$.\n",
    "In order for the hash tables operations to run in constant time, we need\n",
    "$$\n",
    "\\alpha = O(1)\n",
    "$$\n",
    "Furthermore, for open addressing we need $\\alpha << 1$.\n",
    "\n",
    "To maintain this, we can grow the number of buckets with the number of objects in the hash table.\n",
    "\n",
    "Furthermore, for every data set and hash function there exists a data set, we can call it the pathological data set, such that the hash function performs poorly.\n",
    "\n",
    "Solutions\n",
    "1. Use a cryptographic hash function [SHA-2](https://en.wikipedia.org/wiki/SHA-2)\n",
    "2. Use randomization\n",
    "\n",
    "    design a family $H$ of hash functions that are picked at random at when initialising the hash table. This is also known as \"Universal Hashing\". The hash function can also be changed when rehashing the entire table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Hashing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $H$ be a set of hash functions that map\n",
    "$$\n",
    "h: U \\mapsto \\{ 0, 1, 2, \\cdots, n-1 \\}\n",
    "$$\n",
    "\n",
    "$H$ is universal iff \n",
    "$$\n",
    "\\forall x, y \\in U \\quad, \\quad x \\neq y \\\\[5pt]\n",
    "p[h(x) = h (y)] \\leq \\frac{1}{n} \\\\[10pt]\n",
    "$$\n",
    "\n",
    "when $h$ is chosen uniformly at random from $H$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example: Hashing IP Addresses\n",
    "\n",
    "Let $U = $ IP addresses of the form,\n",
    "$$\n",
    "(x_1, x_2, x_3, x_4) \\; \\text{for} \\; x_i \\in \\{0, 1, 2, \\cdots, 255\\}\n",
    "$$\n",
    "\n",
    "Let $n = $ a prime.\n",
    "\n",
    "Define one hash function $h_a$ for each 4-tuple\n",
    "$$\n",
    "a = (a_1, a_2, a_3, a_4) \\; \\text{for} \\; a_i \\in \\{0, 1, 2, \\cdots, n-1\\}\n",
    "$$\n",
    "\n",
    "This produces $n^4$ such functions.\n",
    "\n",
    "For an IP address $i$\n",
    "$$\n",
    "h_a: i \\mapsto a \\cdot i\\mod{n} \\\\[10pt]\n",
    "h_{(a_1, a_2, a_3, a_4)}{(x_1, x_2, x_3, x_4)} = a_1x_1 + a_2x_2 + a_3x_3 + a_4x_4 \\mod{n}\n",
    "$$\n",
    "\n",
    "Finally, the universal set $H$ is the set of all $h_a$\n",
    "$$\n",
    "H = \\{ h_a | a\\}\n",
    "$$\n",
    "\n",
    "Proof:\n",
    "\n",
    "Consider distinct IP addresses $(x_1, x_2, x_3, x_4)$ and $(y_1, y_2, y_3, y_4)$ having a collision.\n",
    "$$\n",
    "h_{a}{(x_1, x_2, x_3, x_4)} = h_{a}{(y_1, y_2, y_3, y_4)} \\\\[10pts]\n",
    "a_1x_1 + a_2x_2 + a_3x_3 + a_4x_4 \\equiv a_1y_1 + a_2y_2 + a_3y_3 + a_4y_4 \\mod{n} \\\\\n",
    "a_4 (x_4 - y_4) \\equiv \\sum_{i=1}^{3}{a_i(y_i - x_i)} \\mod{n} \n",
    "$$\n",
    "\n",
    "Consider $a_4$ as a random variables given that $a_1, a_2, a_3$ are already fixed.\n",
    "\n",
    "Further, assume that $n$ is sufficiently larger than $x_4$ and $y_4$ such that \n",
    "$$\n",
    "x_4 - y_4 \\not\\equiv 0 \\mod{n}\n",
    "$$\n",
    "Where $g = (x_4 - y_4)$\n",
    "\n",
    "Therefore the probability of such a collision reduces to the number of solutions of the equation\n",
    "$$\n",
    "a_4 \\times g \\equiv m \\mod{n}\n",
    "$$\n",
    "\n",
    "Assume that there exists two solutions $k_1$, $k_2$ to this equation.\n",
    "$$\n",
    "k_1 \\times g \\equiv k_2 \\times g \\equiv m \\mod{n} \\\\\n",
    "k_1 \\times g - k_2 \\times g \\equiv 0 \\mod{n} \\\\\n",
    "(k_1 - k_2) \\times g \\equiv 0 \\mod{n}\n",
    "$$\n",
    "\n",
    "Since $n$ is prime and $g$ is not congruent to $0$ modulo $n$, this implies that\n",
    "$$\n",
    "k_1 - k_2 \\equiv 0 \\mod{n} \\\\\n",
    "k_1 \\equiv k_2 \\mod{n}\n",
    "$$\n",
    "\n",
    "Therefore, since $a_4$ can only take values from $\\{0, 1, 2, \\cdots, n-1\\}$. There is only one such value of $a_4$ such that the congruence is satisfied. \n",
    "\n",
    "Since only $1$ out of $n$ choices for $a_4$ satisfies the congruence and $a_4$ is uniformly chosen at random.\n",
    "$$\n",
    "p( \\text{collision} ) = \\frac{1}{n}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining: Constant-Time Gaurantee"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hash table implemented with chaining and the hash function $h$ is chosen uniformly at random from a universal family $H$.\n",
    "\n",
    "We can gaurantee that lookup insert and delete operations run in $O(1)$.\n",
    "- Given as an expectation over random choice of hash function $h$\n",
    "- Load of the hash table $\\alpha = O(1)$\n",
    "- Hash function takes $O(1)$ time to evaluate\n",
    "\n",
    "We will analyse the running time of an unsuccesful lookup as an upper-bound on the running time of the other operations.\n",
    "\n",
    "In general, the running time for a hash function containing the set $S \\subset U$\n",
    "$$\n",
    "O(1) + O(\\text{list length in} \\; A[h(x)])\n",
    "$$\n",
    "Where $x \\not\\in S$ and the list length depends on the random choice of $h$\n",
    "\n",
    "Let $L =$ list length in $A[h(x)]$\n",
    "\n",
    "For $y \\in S$, define\n",
    "$$\n",
    "Z_y = \n",
    "\\begin{cases}\n",
    "1 & \\text{if} \\; h(y) = h(x) \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "Then,\n",
    "$$\n",
    "L = \\sum_{y \\in S}{Z_y}\n",
    "$$\n",
    "Therefore,\n",
    "$$\n",
    "E(L) = \\sum_{y \\in S}{E(Z_y)} \\\\[5pt]\n",
    "= \\sum_{y \\in S}{p(h(y) = h(x))} \\\\[5pt]\n",
    "\\leq \\sum_{y \\in S}{\\frac{1}{n}} = \\frac{\\lvert S \\rvert}{n} \\\\[5pt]\n",
    "= \\alpha = O(1)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Addressing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In open addressing, we enforce that there is only object per slot. To do so, each hash function will procude a probe sequence for each possible key $x$.\n",
    "\n",
    "Heuristic Analysis:\n",
    "\n",
    "We assume that each of the $n!$ probe sequences are equally likely. Then we can show that the insertion time\n",
    "$$\n",
    "\\approx \\frac{1}{1-\\alpha}\n",
    "$$\n",
    "\n",
    "Proof: By a crude upper bound\n",
    "$$\n",
    "p(\\text{finding an empty slot by random}) = 1 - \\alpha \n",
    "$$\n",
    "\n",
    "Let $N$ be the number of probe attempts before finding an empty slot.\n",
    "$$\n",
    "E(N) = 1 + \\alpha \\times E(N) \\\\\n",
    "\\therefore \\quad E(N) = \\frac{1}{1-\\alpha}\n",
    "$$\n",
    "\n",
    "This tends to be the case for double hashing.\n",
    "\n",
    "For Linear probing the analysis is different since the heuristic assumption is false.\n",
    "\n",
    "Instead we will assume, initial probe is uniformly random and independant for different keys\n",
    "\n",
    "The insertion time can then be expected to be (Knuth 1962)\n",
    "$$\n",
    "\\approx \\frac{1}{(1-\\alpha)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Filters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supports the same operations as a hash table. However,\n",
    "1. \\+ More space efficient than a hash table\n",
    "2. \\- Can't store as associated object\n",
    "3. \\- No Deletions\n",
    "4. \\- Small false positive probability\n",
    "\n",
    "Most suited for remember if you've seen something before or not.\n",
    "\n",
    "Implementing a Bloom Filter.\n",
    "\n",
    "1. We define an array of $n$ bits, such that \n",
    "$$\n",
    "\\frac{n}{\\lvert s \\rvert} = \\text{\\# of bits per object in} \\;S\n",
    "$$\n",
    "\n",
    "2. $k$ hash functions $h_1, \\cdots h_k$ such that $k$ is a small constant\n",
    "\n",
    "```\n",
    "Insert(x):\n",
    "    for i=1, 2, ... ,k\n",
    "        set A[h_i(x)] = 1\n",
    "\n",
    "Lookup(x):\n",
    "    for i=1, 2, ... ,k\n",
    "        if A[h_i(x)] != 1\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "```\n",
    "\n",
    "Since we never set bits back to 0, there will be no false negatives. Furthermore, at the point where the bloom filter becomes \"full\", every element will become a false positive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we will assume that each value of $h_i(x)$ is uniformly random and independant across all $i$ and $x$.\n",
    "\n",
    "Given $n$ bits, $k$ hash functions and a data set $S$.\n",
    "$$\n",
    "p(\\text{a given bit is set to 1}) = 1 - \\left(1 - \\frac{1}{n}\\right)^{k\\lvert S \\rvert}\n",
    "$$\n",
    "\n",
    "For any given bit, there will be $k \\times \\lvert S \\rvert$ attempts where the bit may be set to 1. Further since the hash functions are uniformly random and independant,\n",
    "$$\n",
    "p(\\text{the bit remains 0}) = \\left(1 - \\frac{1}{n}\\right)^{k\\lvert S \\rvert}\n",
    "$$.\n",
    "\n",
    "Therefore, the probability that the bit is set to 1 at least once, is as stated above.\n",
    "\n",
    "Applying the upper bound\n",
    "$$\n",
    "1 - x \\leq e^{-x} \\\\\n",
    "p(\\text{a given bit is set to 1}) \\leq 1 - e^{-\\frac{ k\\lvert S \\rvert}{n}}\n",
    "$$\n",
    "\n",
    "Let $b$ be the number of bits per object, \n",
    "$$\n",
    "b = \\frac{n}{\\lvert S \\rvert}\n",
    "$$\n",
    "Then,\n",
    "$$\n",
    "p(\\text{a given bit is set to 1}) \\leq 1 - e^{\\frac{-k}{b}}\n",
    "$$\n",
    "\n",
    "For a given object $x \\not\\in S$,\n",
    "$$\n",
    "p(\\text{false positive for } x) = \\left(1 - e^{\\frac{-k}{b}}\\right)^{k}\n",
    "$$\\\n",
    "\n",
    "To optimise the bloom filter, we fix a value of $b$ that suits our application, then we minimise the false positive probability $\\epsilon$. \n",
    "$$\n",
    "\\epsilon = \\left(1 - e^{\\frac{-k}{b}}\\right)^{k} \\\\[10pt]\n",
    "$$\n",
    "To find a minimum, we solve for \n",
    "$$\n",
    "\\frac{\\partial \\epsilon}{\\partial k} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\epsilon}{\\partial k} = \\frac{\\partial}{\\partial k}\\left(e^{k\\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)}}\\right) \\\\[10pt]\n",
    "= \\left(1 - e^{\\frac{-k}{b}}\\right)^{k} \\times \\frac{\\partial}{\\partial k}\\left(k\\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)}\\right) \\\\[10pt]\n",
    "\\implies \\frac{\\partial}{\\partial k}\\left(k\\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)}\\right) = 0 \\\\[10pt]\n",
    "\\frac{\\partial}{\\partial k}\\left(k\\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)}\\right) = \\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)} + \\frac{k}{1 - e^{\\frac{-k}{b}}} \\times \\frac{e^{\\frac{-k}{b}}}{b} \\\\[10pt]\n",
    "=\\ln{\\left(1 - e^{\\frac{-k}{b}}\\right)} + \\frac{k}{b}\\frac{1}{e^{\\frac{k}{b}} -1}\n",
    "$$\n",
    "\n",
    "At this point lets introduce $g = e^{\\frac{k}{b}}$. Then,\n",
    "$$\n",
    "\\ln{\\left(1 - \\frac{1}{g}\\right)} + \\frac{\\ln{g}}{g -1} = 0 \\\\[10pt]\n",
    "\\ln{(g -1)} - \\ln{g} + \\frac{\\ln{g}}{g -1} = 0 \\\\[10pt]\n",
    "(g -1)\\ln{(g -1)} - \\ln{g}(g -1) + \\ln{g} = 0 \\\\[10pt]\n",
    "(g -1)\\ln{(g -1)} - \\ln{g}(g -2) = 0 \\\\[10pt]\n",
    "$$\n",
    "\n",
    "Notice that $g=2$ will be a root of both $\\ln{(g -1)}$ and $(g -2)$. Therefore a valid solution is\n",
    "$$\n",
    "e^{\\frac{k}{b}} = 2 \n",
    "\\implies \\frac{k}{b} = \\ln{2}\n",
    "\\implies k = b\\ln{2}\n",
    "$$\n",
    "\n",
    "This gives an overall false positive error\n",
    "$$\n",
    "\\epsilon = \\left(\\frac{1}{2}\\right)^{\\ln{2} \\times b}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Theory Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Recall that a set $H$ of hash functions (mapping the elements of a universe $U$ to the buckets $\\{0,1,2,\\cdots,n−1\\}$ ) is universal if for every distinct $x, y\\in U$, the probability $p[h(x)=h(y)]$ that $x$ and $y$ collide, assuming that the hash function $h$ is chosen uniformly at random from $H$, is at most $1/n$. \n",
    "\n",
    "In this problem you will prove that a collision probability of $1/n$ is essentially the best possible. \n",
    "\n",
    "Precisely, suppose that $H$ is a family of hash functions mapping $U$ to $\\{0,1,2,\\cdots,n−1\\}$, as above. Show that there must be a pair $x, y\\in U$ of distinct elements such that, if $h$ is chosen uniformly at random from $H$, then $p[h(x)=h(y)] \\geq \\frac{1}{n} - \\frac{1}{\\lvert U \\rvert}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a lower bound of the probability of a collision, we can assume that the randomly chosen hash function exhibits perfect hashing for $n$ out of $\\lvert U \\rvert$ keys. Then for the remaining,\n",
    "$$\n",
    "\\lvert U \\rvert - n\n",
    "$$\n",
    "keys a collision is garunteed to occur.\n",
    "\n",
    "Therefore, for any hash function there exist a pair of keys $x$ that belongs to the $n$ perfect hashes and $y$ belonging to the remaining keys,\n",
    "$$\n",
    "p[h(x) = h(y)] \\\\\n",
    "\\geq p(\\text{choosing a collision key}) \\times p(\\text{choosing a key that belongs to the perfect set}) \\\\\n",
    "= \\frac{\\lvert U \\rvert - n}{\\lvert U \\rvert} \\times \\frac{1}{n} \\\\\n",
    "= \\frac{\\lvert U \\rvert - n}{\\lvert U \\rvert n} = \\frac{1}{n} - \\frac{1}{\\lvert U \\rvert}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assingment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this problem is to implement a variant of the 2-SUM algorithm covered in this week's lectures.\n",
    "\n",
    "The file contains 1 million integers, both positive and negative (there might be some repetitions!).This is your array of integers, with the $i^{th}$ row of the file specifying the $i^{th}$ entry of the array.\n",
    "\n",
    "Your task is to compute the number of target values $t$ in the interval [-10000,10000] (inclusive) such that there are distinct numbers $x$, $y$ in the input file that satisfy $x+y=t$ . (NOTE: ensuring distinctness requires a one-line addition to the algorithm from lecture.)\n",
    "\n",
    "Write your numeric answer (an integer between 0 and 20001) in the space provided.\n",
    "\n",
    "OPTIONAL CHALLENGE: If this problem is too easy for you, try implementing your own hash table for it. For example, you could compare performance under the chaining and open addressing approaches to resolving collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Generic, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "class Hash(Protocol, Generic[T]):\n",
    "    def __iter__(self):\n",
    "        ...\n",
    "    \n",
    "    def add(self, item: T):\n",
    "        ...\n",
    "    \n",
    "    def discard(self, item: T):\n",
    "        ...\n",
    "\n",
    "def two_sum(arr: list[int], hash: Hash[int], targets: set[int]):\n",
    "    found = set()\n",
    "\n",
    "    iters = 0\n",
    "    cycle = 0\n",
    "\n",
    "    for x in arr:\n",
    "        iters += 1\n",
    "        \n",
    "        if iters // 1000 > cycle:\n",
    "            cycle += 1\n",
    "            completion = (iters / len(arr)) * 100\n",
    "            print(f'progress: {format(completion, \".2f\")}%, numbers: {iters}', end='\\r')\n",
    "\n",
    "        for sum in targets:\n",
    "            if sum - x in hash:\n",
    "                found.add(sum)\n",
    "\n",
    "        targets = targets.difference(found)\n",
    "\n",
    "    completion = (iters / len(arr)) * 100\n",
    "    print(f'progress: {format(completion, \".2f\")}%, numbers: {iters}', end='\\r')\n",
    "    \n",
    "    return len(found)\n",
    "\n",
    "def populate_hash(arr: list[int], hash: Hash[int]):\n",
    "    for x in arr:\n",
    "        hash.add(x)\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    with open('Week 4 2-SUM.txt') as f:\n",
    "        for line in f:\n",
    "            yield int(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [x for x in data()]\n",
    "hash = populate_hash(arr, set())\n",
    "targets = {x for x in range(-10_000, 10_000 +1)}\n",
    "\n",
    "count = two_sum(arr, hash, targets)\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing is taking so long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_two_sum(sorted_arr: list[int]):\n",
    "    targets = set()\n",
    "\n",
    "    front_idx = 0\n",
    "    end_idx = len(sorted_arr) -1\n",
    "\n",
    "    while front_idx < end_idx:\n",
    "        testsum = sorted_arr[front_idx] + sorted_arr[end_idx]\n",
    "\n",
    "        if testsum < -10_000: # sum is outside the range, make sum larger\n",
    "            front_idx += 1\n",
    "        elif testsum > 10_000: # sum is outside the range, make sum smaller\n",
    "            end_idx -= 1\n",
    "        else: # sum is within the range, count possibilites whilst making sum smaller\n",
    "            targets.add(testsum)\n",
    "            for r in range(end_idx, front_idx, -1):\n",
    "                testsum = sorted_arr[front_idx] + sorted_arr[r]\n",
    "        \n",
    "                if testsum < -10_000:\n",
    "                    break\n",
    "                else:\n",
    "                    targets.add(testsum)\n",
    "            \n",
    "            front_idx += 1\n",
    "    \n",
    "    return len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [x for x in data()]\n",
    "arr.sort()\n",
    "\n",
    "sorted_two_sum(arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I must give credit to [En Lin](https://www.coursera.org/learn/algorithms-graphs-data-structures/discussions/forums/wuxqB3b0EeamjgocByS1BQ/threads/peidUXM7EeiD9g6PBVjxjg). Brilliant. \n",
    "\n",
    "The sorting is faster since, sorting should run in $O(n\\log{n})$ while the hashing would run in $O(n) \\times O(1)$ where we compare\n",
    "$$\n",
    "\\log{n} \\approx 6 \\\\\n",
    "O(1) \\approx 20,000\n",
    "$$\n",
    "Since in the worst case we have to check all 20,000 sums for each number in the hash."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
