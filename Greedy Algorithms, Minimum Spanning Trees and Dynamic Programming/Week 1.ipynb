{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivating Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Internet Routing\n",
    "\n",
    "Let the vertices of the graph be\n",
    "\n",
    "1. Hosts / Servers\n",
    "2. Routers\n",
    "\n",
    "And whose edges are directed if there is a physical / wireless connection between the vertices.\n",
    "\n",
    "A fundamental question would be to determine what the shortest path / minimising path is.\n",
    "\n",
    "However, unlike the case where we could use Dijkstra's algorithm, the internet graph is too large and too dynamic to fit in memory. \n",
    "\n",
    "This calls for an algorithm that only computes local information.\n",
    "\n",
    "This is known as the [Bellman-Ford](https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm) algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequence Alignment\n",
    "\n",
    "Given two strings $s_1$, $s_2$ over a set of characters $A$. For example,\n",
    "$$\n",
    "A = \\{\\text{A}, \\text{C}, \\text{G}, \\text{T}\\} \\\\[10pt]\n",
    "s_1 = \\text{AGGCT} \\\\\n",
    "s_2 =  \\text{AGGGCA} \\\\\n",
    "$$\n",
    "\n",
    "Compute how \"similar\" the two strings are.\n",
    "\n",
    "We might want to do this to\n",
    "\n",
    "1. Extrapolate the function of genome substrings\n",
    "2. Infer evolutionary proximity\n",
    "\n",
    "To be precise about \"similarity\", let us first define the distance between two strings $d(s_1, s_2, \\alpha)$ to be,\n",
    "$$\n",
    "d(s_1, s_2, \\alpha) = \\sum{\\text{penalties}(\\alpha)} \\\\[20pt]\n",
    "$$\n",
    "for a given alignment $\\alpha$ where\n",
    "$$\n",
    "\\text{penalties}(\\alpha) = \n",
    "\\begin{cases}\n",
    "    \\text{gap} \\geq 0 & \\text{for each gap in} \\; \\alpha \\\\\n",
    "    \\text{mismatch} \\geq 0 & \\text{for each mismatch in} \\; \\alpha \\\\\n",
    "    \\quad \\vdots\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then the \"similairity\" of the two strings is the alignment of the strings that minimises the distance.\n",
    "$$\n",
    "\\text{similarity} = \\min_{\\alpha}{d(s_1, s_2, \\alpha)}\n",
    "$$\n",
    "\n",
    "This is known as the [Needleman-Wunsch Score](https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm#:~:text=The%20Needleman%E2%80%93Wunsch%20algorithm%20is%20still%20widely%20used%20for%20optimal,alignments%20having%20the%20highest%20score.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A greedy algorithm iteratively makes \"myopic\" decisions in the hope that things work out in the end.\n",
    "\n",
    "The running time of greedy algorithms are generally easier to compute. However, proofs of correctness are not always obvious, generally there are few methods,\n",
    "\n",
    "1. Induction (\"greedy stays ahead\")\n",
    "2. \"Exchange argument\" (where we show via transformations that an optimal solution is identical to the greedy solution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Caching Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have two memory types \n",
    "- small fast memory\n",
    "- big slow memory\n",
    "\n",
    "The goal is to process a sequence of \"page requests\".\n",
    "\n",
    "On a cache miss / \"page fault\", we need to bring something from memory into the cache. To do so we will have to evict something from the cache to make room. Who should be evicted?\n",
    "\n",
    "The optimal algorithm is known as the \"furthest-in-future\" algorithm (Belady 1960).However, this algorithm assumes that we know the future, so its in unimplemtable. Instead, this serves as a jumping off point for more practical algorithms.\n",
    "\n",
    "- Least Recently Used\n",
    "\n",
    "    Assumes that data that was requested recently will be requested soon, and data that was requested a long time ago, will be requested in-frequently.\n",
    "\n",
    "Proof: TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Scheduling Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have a single processing thread, with many jobs to process. In what order should we sequence the jobs?\n",
    "\n",
    "Each job $j$ has two parameters\n",
    "1. a weight $w_j$\n",
    "2. a length $l_j$\n",
    "\n",
    "Define the completion time $c_j$ of a job $j$ \n",
    "$$\n",
    "c_j = \\sum_{i \\leq j}{l_i}\n",
    "$$\n",
    "That is, the time elapsed until the completion of job $j$.\n",
    "\n",
    "One way to measure the quality of a sequence of jobs is by computing the weighted sum $s$ of completion time\n",
    "$$\n",
    "s = \\sum{w_j \\cdot c_j}\n",
    "$$\n",
    "\n",
    "We seek an algorithm that minimises $s$.\n",
    "\n",
    "If $w_j$ is constant, then we want to schedule smaller $l_j$ first.\n",
    "\n",
    "Likewise if $l_j$ is constant, then we want to schedule larger $w_j$ first.\n",
    "\n",
    "In the case that $w_i > w_j$ and $l_i > l_j$ or vice versa, we will need to device a score to order the jobs.\n",
    "\n",
    "This score should increase with $w$ and decrease with $l$. These could be forms of\n",
    "\n",
    "- $w_j - l_j$\n",
    "- $\\frac{w_j}{l_j}$\n",
    "\n",
    "It can be shown via a counter example that the difference score is not always correct. The following is a proof of the correctness of the ratio score.\n",
    "\n",
    "Proof by \"Exchange Argument\"\n",
    "\n",
    "Let\n",
    "$$\n",
    "\\sigma = \\text{greedy schedule} \\\\\n",
    "\\sigma^* = \\text{optimal schedule}\n",
    "$$\n",
    "\n",
    "We will proceed by contradiction, showing that we are able to generate a schedule more optimal than $\\sigma^*$.\n",
    "\n",
    "Assumptions:\n",
    "1. all $\\frac{w_j}{l_j}$ are distinct\n",
    "2. WLOG that $\\frac{w_1}{l_1} > \\frac{w_2}{l_2} > \\cdots > \\frac{w_n}{l_n}$ via a renaming of jobs\n",
    "\n",
    "Therefore\n",
    "$$\n",
    "\\sigma = 1, 2, \\cdots, n\n",
    "$$\n",
    "\n",
    "Since $\\sigma^* \\neq \\sigma$, there are consecutive jobs $i, j$ with $i > j$.\n",
    "\n",
    "Then suppose we exchange the jobs $i, j$ in $\\sigma^*$, leaving all other jobs unchanged. This produces a new schedule $\\sigma^{**}$.\n",
    "\n",
    "Using assumption 2, we know that since $i > j$\n",
    "$$\n",
    "\\frac{w_i}{l_i} < \\frac{w_j}{l_j} \\\\\n",
    "\\implies w_il_j < w_jl_i\n",
    "$$\n",
    "\n",
    "Let $s(\\sigma)$ return the score of a schedule $\\sigma$. Then,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "s(\\sigma^{**}) = s(\\sigma^*) & - w_i(\\alpha + l_i) - w_j(\\alpha + l_i + l_j) \\\\\n",
    "& + w_j(\\alpha + l_j) + w_i(\\alpha + l_j + l_i)\n",
    "\\end{aligned} \\\\[10pt]\n",
    "\\implies s(\\sigma^{**}) = s(\\sigma^*) + w_il_j - w_jl_i\n",
    "$$\n",
    "Where $\\alpha$ is the sum of the job lengths $l_k$ for $k < i$.\n",
    "\n",
    "Further, using assumption 2. Since\n",
    "$$\n",
    "w_il_j < w_jl_i \\\\[10pt]\n",
    "w_il_j - w_jl_i < 0 \\\\[10pt]\n",
    "\\implies s(\\sigma^{**}) < s(\\sigma^*)\n",
    "$$\n",
    "\n",
    "This is a contradiction as $\\sigma^*$ was defined to be the optimal. Therefore, there is no more optimal solution than the solution produced by the greedy algorithm.\n",
    "\n",
    "We can also examine assumption 1 that the ratios are distinct. In the case that the ratios are equal,\n",
    "$$\n",
    "\\frac{w_i}{l_i} = \\frac{w_j}{l_j} \\\\[10pt]\n",
    "w_il_j - w_jl_i = 0 \\\\[10pt]\n",
    "\\implies s(\\sigma^{**}) = s(\\sigma^*) = s(\\sigma)\n",
    "$$\n",
    "\n",
    "Therefore when there are equal ratios, then the greedy algorithm produces a squence that will have the same score as the optimal schedule."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Spanning Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to construct a tree that connects a bunch of objects together as cheaply as possible.\n",
    "\n",
    "This will go over \n",
    "- [Prim's Algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm)\n",
    "- [Kruskal's Algorithm](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm)\n",
    "\n",
    "both of which run in $O(m\\log{n})$ for $m$ edges adn $n$ vertices when implemented using suitable data structures.\n",
    "\n",
    "Given an undirected graph $G=(V,E)$ where,\n",
    "- the graph is represented as an adjacency list\n",
    "- there is a cost $c_e$ for each edge $e \\in E$, $c_e \\in \\mathbb{R}$\n",
    "\n",
    "Return a minimum cost tree $T \\in E$ that spans all the vertices. Where\n",
    "- $T$ is acyclic\n",
    "- the subgraph $(V, T)$ is connected\n",
    "\n",
    "To simply the discussion, we will make 2 assumptions\n",
    "1. $G$ is already connected\n",
    "    \n",
    "    If $G$ was not connected then the solution $T$ does not exist. It takes linear time to check if $G$ is connected via BFS/DFS\n",
    "\n",
    "2. $c_e$ values are distinct\n",
    "\n",
    "    Both algorithms will still find $T$ regardless of how ties are broken. This assumption serves to make the following dicussion more steamlined.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prim's Algorithm\n",
    "\n",
    "Similar to Dijkstra's Algorithm, we expand the horizon of touched nodes one at a time, each time being \"greedy\" and going for the cheapest edge.\n",
    "\n",
    "```\n",
    "Prims(G):\n",
    "\n",
    "    X = [s] \\\\arbitrary add\n",
    "    T = { }\n",
    "\n",
    "    while X is not V:\n",
    "\n",
    "        find cheapest e = (u, p) \n",
    "            where u in X but p not in X\n",
    "        \n",
    "        add e to T\n",
    "        add p to X\n",
    "\n",
    "    return T, X\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proofs of Correctness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proof that a spanning tree $T^*$ is computed\n",
    "\n",
    "We define a \"cut\" to be a pair of non-empty sets $A$, $B$\n",
    "$$\n",
    "c = (A, B)\n",
    "$$\n",
    "\n",
    "1. Empty Cut Lemma\n",
    "$$\n",
    "\\text{graph is NOT connected} \\iff \\exists (A,B) \\; \\text{with no crossing edges}\n",
    "$$\n",
    "\n",
    "2. Double Crossing Lemma\n",
    "\n",
    "    Sps the cycle $C \\subseteq E$ has an edge crossing the cut $(A, B)$. Then do does some other edge of $C$.\n",
    "\n",
    "    This means that if $e$ is the only edge crossing the cut $(A, B)$ then it is not in any cycle\n",
    "\n",
    "To show that Prim's algorithm outputs a spanning tree, we will prove that\n",
    "\n",
    "1. Algorithm maintians an invariant that $T$ spans $X$\n",
    "2. Algorithm does not get stuck with $X \\neq V$\n",
    "3. Algorithm never creates a cycle\n",
    "\n",
    "For the algorithm to get stuck, there must exists a cut of the graph that has no crossing edges. By the Empty Cut Lemma, this means that the graph is not connected. This cannot be the case as it violates the first assumption of the algorithm.\n",
    "\n",
    "For the algorithm to create a cycle, there must exist in the set $X$ a cut that has two crossing edges. Since the algorithm only includes one further edge per cut of the graph, each edge in the algorithm is a \"lone edge\". By the Double Crossing Lemma, this means that the addition of each each cannot create a cycle.\n",
    "\n",
    "The algorithm maintains the invariant by adding each node and one edge to $T$, therefore by induction the invariant is maintained.\n",
    "\n",
    "Thus Prim's algorithm produces a spanning tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Proof that $T^*$ is minimum\n",
    "\n",
    "To prove that the output is a minium, we will use the \"minimum cut property\".\n",
    "\n",
    "Consider an edge $e$ of $G$, \n",
    "$$\n",
    "\\exists (A, B) \\; \\text{such that} \\; e \\; \\text{is the cheapest edge} \\implies  e \\; \\text{belongs to the MST of} \\; G \n",
    "$$\n",
    "\n",
    "The minimum cut property trivially implies the correctness of Prim's algorithm, since the alogrithm only includes edges that satisfy the minimum cut property, that is, for intermediate cut, the algorithm selects the cheapest edge to add to the spanning set $T$.\n",
    "\n",
    "Proof of the Minimum Cut Property. \n",
    "\n",
    "We will proceed with a proof by contradiction using an exchange argument.\n",
    "\n",
    "Suppose there exists a cut $(A, B)$ with crossing edges $e_1, e_2, \\cdots, e_n$, for $n \\geq 2$. In the case where there is only one crossing edge this edge must be included in the MST as the tree would not be connected otherwise.\n",
    "\n",
    "WLOG let $e_1$ be the cheapest edge. Further, we will assume that $e_1$ does NOT exists in the MST. \n",
    "\n",
    "We then add $e_1$ into the MST. This necessarily creates a cycle $C$. \n",
    "\n",
    "By the double crossing lemma, there must be another edge $e_i$ that \n",
    "1. crosses the cut $(A, B)$\n",
    "2. is more expensive than $e_1$\n",
    "\n",
    "Then, we will show that exchanging $e_1$ with any suitable $e_i$ results in a cheaper MST, which would be a contradiction.\n",
    "\n",
    "It is required to show that swapping $e_1$ with $e_i$ results in a valid spanning tree. Before adding $e_1$, it is assumed that the spanning tree is complete. That is\n",
    "1. there exists a path from any node to any other node\n",
    "2. the tree is acyclic\n",
    "\n",
    "Upon the addition of $e_1$, this therefore necessarily creates one cycle, as $e_1$ would add a new path between the nodes at the end points of $e_1$ which would be distinct from the path that already exists in the MST. \n",
    "\n",
    "Further, note that when removing any one edge from an existing cycle, each node in the cycle remains connected. This is the case, since for nodes in a cycle, there are exactly two different paths that connect them. One of these path necessarily contains the edge to be removed, and the other does not.\n",
    "\n",
    "Therefore, replacing $e_1$ with $e_i$ results in a valid spanning tree."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Straighforward implementation\n",
    "\n",
    "Inspecting the pseudo-code, there are\n",
    "1. $O(n)$ iterations for $n$ vertices\n",
    "2. $O(m)$ time per iteration for $m$ edges\n",
    "\n",
    "Resulting in $O(mn)$ time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heap implementation\n",
    "\n",
    "A heap can speedup the repeated computation of minimums to $O(\\log{n})$. \n",
    "\n",
    "If the heap is used to store edges, where the keys are the edge costs, we can acheive $O(m\\log{n})$ running time. In the implementation of such an algorithm, it will be important to keep track of only the edges that cross the \"frontier\"\n",
    "\n",
    "If the heap is used to store nodes, we can store\n",
    "1. Nodes in $V-X$\n",
    "2. For $v \\in V-X$, key[$v$] = cheapest edge $(u,v)$ for $u \\in X$ \n",
    "\n",
    "This can be initialised in time\n",
    "$$\n",
    "O(m + n\\log{n}) = O(m\\log{n})\n",
    "$$\n",
    "\n",
    "Where key computations cost $O(m)$, for $O(n-1)$ Heap inserts.\n",
    "\n",
    "In order to maintain the heap invariant after each extract min,\n",
    "```\n",
    "when v is added to X:\n",
    "\n",
    "    for each edge (v, w):\n",
    "        if w in V-X:\n",
    "            Delete w from heap\n",
    "            Recompute key[w] := min(key[w], cost for (v,w))\n",
    "            re-insert w\n",
    "```\n",
    "\n",
    "In general, there will be $O(m)$ heap operations,\n",
    "- $(n-1)$ intialisation inserts\n",
    "- $(n-1)$ extract mins\n",
    "- each edge $(v,w)$ triggers a re-key\n",
    "\n",
    "Therefore overall $O(m\\log{n})$ time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
