{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A mapping between each character in an alphabete and binary string.\n",
    "\n",
    "A standard approach would be to use fixed length codes. However we can do better with variable length codes. However, variable length codes may lead to ambigious messages. Therefore we will insist that these variable length codes are prefix-free\n",
    "\n",
    "A Prefix-free code is an encoding, such that for every pair of characters in an alphabet, neither of the encoding is a prefix of the other.\n",
    "\n",
    "An example of this\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{A} &\\rightarrow 0 \\\\\n",
    "\\text{B} &\\rightarrow 10 \\\\\n",
    "\\text{C} &\\rightarrow 110 \\\\\n",
    "\\text{D} &\\rightarrow 111 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We will use variable length encodings to take advantage of character frequencies. For instance, encoding more frequent characters with fewer bits would lead to much better compression.\n",
    "\n",
    "Given an alphabet an frequencies, how can we optimise the compression of the binary encoding?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes as Trees\n",
    "\n",
    "We can think of binary codes as binary trees. For instance consider the following examples\n",
    "\n",
    "![exampleTrees](img/binary%20code%20tree.png)\n",
    "\n",
    "Notice how the second example is variable lenght, but not prefix free. We can see this visually as there are alphabets whose nodes are \"parents\" of other alphabets.\n",
    "\n",
    "![prefixFree](img/prefix%20free%20tree.png)\n",
    "\n",
    "In general,\n",
    "1. left child egdes -> 0, right child edges -> 1\n",
    "2. for each character there is only one node\n",
    "3. encoding of the character = bits along the root node path\n",
    "4. prefix-free = labelled nodes are the leaves\n",
    "\n",
    "To decode, simply follow the tree until you hit a leaf node. Output the leaf character. Repeat\n",
    "\n",
    "Further, note that\n",
    "$$\n",
    "\\text{encoding length of} \\; i \\in \\Phi = \\text{depth of} \\; i \\; \\text{in tree}\n",
    "$$\n",
    "\n",
    "Where $i$ is a character from the alphabet $\\Phi$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Given a probability $p_i$ for each character $i \\in \\Phi$,\n",
    "\n",
    "if $T =$ tree with leaves $\\leftrightarrow$ symbols of $\\Phi$, let\n",
    "$$\n",
    "L(T) = \\sum_{i \\in \\Phi}{(p_i \\times [\\text{depth of} \\; i \\; \\text{in} \\; T])}\n",
    "$$\n",
    "\n",
    "We seek to minimise $L(T)$ over all $T$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman Codes\n",
    "\n",
    "There is a natrual but suboptimal approach to build the tree from the top-down in a divide and conquer like algorithm.\n",
    "\n",
    "Huffmans optial idea is to build the tree from the bottom-up using successive mergers.\n",
    "\n",
    "We will take a greedy approach.\n",
    "\n",
    "- Which pair of symbols are \"safe\" to merge?\n",
    "\n",
    "Observe that the final encoding length of $i$ is equal to the number of merges the subtree endures. Therefore for each merger, we increase the number of bits in those characters encoding by 1.\n",
    "\n",
    "This informs our decision to merge the least frequent symbols first.\n",
    "\n",
    "How should we recurse after iterating these single characters?\n",
    "\n",
    "After merging two characters, lets introduce a new \"hidden-layer\" symbol. Such that\n",
    "$$\n",
    "p_{\\text{hidden layer}} = p_a + p_b\n",
    "$$\n",
    "\n",
    "As a result, mergers keep track of the total frequency of their children.\n",
    "\n",
    "Psuedo-code\n",
    "```\n",
    "Hufffmans(S)\n",
    "\n",
    "    Find a, b in S, such that they have the smallest frequencies\n",
    "\n",
    "    Let S* = S with a and b fused into a single node\n",
    "\n",
    "    p_ab = p_a + p_b\n",
    "\n",
    "    Recurse on S* to compute the Tree T\n",
    "\n",
    "    Return T\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of Corectness\n",
    "\n",
    "We aim to show that the binary tree produced by Huffmans algorithm minimises $L(T)$.\n",
    "\n",
    "Proof by induction on $n = \\lvert\\Phi\\rvert$\n",
    "\n",
    "Base case $n = 2$\n",
    "- Tree is optimal with 1 bit per symbol\n",
    "\n",
    "Assume $n=k$ is optimal. For $n=k+1$,\n",
    "\n",
    "Let $\\Phi^\\prime$ be $\\Phi$ with $a$, $b$ replaced by a \"hidden layer\"/\"meta-symbol\" $ab$\n",
    "\n",
    "Define $p_{ab} = p_a + p_b$\n",
    "\n",
    "Let $T^\\prime$ be the tree for $\\Phi^\\prime$ and $T$ be the tree for $\\Phi$. For every such pair $T^\\prime$ and $T$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(T) - L(T^\\prime) &= p_a \\times [\\text{depth of} \\; a \\; \\text{in} \\; T] \\\\\n",
    "&+ p_a \\times [\\text{depth of} \\; b \\; \\text{in} \\; T] \\\\\n",
    "&- p_{ab} \\times [\\text{depth of} \\; ab \\; \\text{in} \\; T^\\prime]\n",
    "\\end{aligned}\n",
    "$$\n",
    "Note that\n",
    "$$\n",
    "p_{ab} = p_a + p_b \\\\\n",
    "$$\n",
    "Further, let\n",
    "$$\n",
    "\\text{depth of} \\; a \\; \\text{in} \\; T = d \\\\\n",
    "\\text{depth of} \\; a \\; \\text{in} \\; T = d \\\\\n",
    "\\text{depth of} \\; ab \\; \\text{in} \\; T^\\prime = d -1\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "L(T) - L(T^\\prime) = dp_a + dp_b - (p_a + p_b)(d -1) \\\\\n",
    "= p_a + p_b\n",
    "$$\n",
    "\n",
    "By an exchange argument.\n",
    "\n",
    "Let $T^*$ be any tree that minimises $L(T)$ for $\\Phi$.\n",
    "\n",
    "Let $x,y$ bt siblings at the deepest level of $T^*$.\n",
    "\n",
    "Obtain a new tree $\\hat{T}$ from $T^*$ by swapping\n",
    "1. $a \\leftrightarrow x$\n",
    "2. $b \\leftrightarrow b$\n",
    "\n",
    "Note that after performing the swap, $\\hat{T}$ will contain the \"meta-node\" $ab$\n",
    "\n",
    "We will show that \n",
    "$$\n",
    "L(\\hat{T}) \\leq L(T^*)\n",
    "$$\n",
    "\n",
    "Since,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(T^*) - L(\\hat{T}) &= (p_x - p_a) \\times [\\text{depth of} \\; x - a \\; \\text{in} \\; T^*] \\\\\n",
    "&+ (p_y - p_b)\\times [\\text{depth of} \\; y - b \\; \\text{in} \\; T^*] \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that since $a$ and $b$ have the smallest frequencies\n",
    "$$\n",
    "(p_x - p_a) \\geq 0 \\\\\n",
    "(p_y - p_b) \\geq 0\n",
    "$$\n",
    "Further since $x$ and $y$ have to be at deeper levels than $a$ and $b$\n",
    "$$\n",
    "[\\text{depth of} \\; x - a \\; \\text{in} \\; T^*] \\geq 0 \\\\\n",
    "[\\text{depth of} \\; y - b \\; \\text{in} \\; T^*] \\geq 0 \n",
    "$$\n",
    "\n",
    "Therefore\n",
    "$$\n",
    "L(T^*) - L(\\hat{T}) \\geq 0  \n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Time\n",
    "\n",
    "Naive implementation: $O(n^2)$ time for $n = \\lvert\\Phi\\rvert$\n",
    "\n",
    "Heap implementation: $O(n\\log{n})$\n",
    "1. keys = frequencies\n",
    "2. during a merge reinsert new meta symbol\n",
    "\n",
    "Even faster: Sorting + $O(n)$ additional work\n",
    "1. manage meta symbols using two queues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming\n",
    "\n",
    "Idea:\n",
    "\n",
    "- Reason about the strucure of an optimal solution in terms of optimal solutions to smaller sub-problems.\n",
    "- Cache / memoise past sub-problem results\n",
    "\n",
    "Key Ingredients:\n",
    "\n",
    "1. Identify a small number of subproblems\n",
    "2. can quickly & correctly solve larger subproblems given the solutions to smaller subproblems \n",
    "3. after solving all subproblems, can quickly compute final solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![whyDynamic](img/WhyDynamic.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Independent Sets in Path Graphs\n",
    "\n",
    "Given a path graph $G = (V, E)$ with nonnegative weights on vertice, return a subset of nonadjacent vertices (an independent set) of maximum total weight.\n",
    "\n",
    "Let $S \\subset V$ be a max-weight independent Set.\n",
    "\n",
    "Let $v_n$ be the last vertex of the path\n",
    "\n",
    "There are two cases. Either $v_n \\notin S$(case 1), or $v_n \\in S$ (case 2).\n",
    "\n",
    "Case 1.\n",
    "\n",
    "Let $G^\\prime=G$ with $v_n$ deleted. Note:\n",
    "1. $S$ is also an IS of $G^\\prime$\n",
    "2. $S$ must be a max-weight IS of $G^\\prime$\n",
    "\n",
    "Case 2.\n",
    "\n",
    "Since $v_n \\in S$, $v_{n-1} \\notin S$.\n",
    "\n",
    "Let $G^{\\prime\\prime} = G$ with $v_{n-1}$, $v_n$ deleted. Note:\n",
    "1. $S - \\{v_n\\}$ is an IS of $G^{\\prime\\prime}$\n",
    "2. $S - \\{v_n\\}$ is also a max-weight IS of $G^{\\prime\\prime}$\n",
    "\n",
    "    - If there exists some $S^*$ that is a larger weight IS than $S$ in $G^{\\prime\\prime}$, then $S^* \\cup \\{v_n\\}$ is better than $S$ in $G$ which is a contradiction\n",
    "\n",
    "\n",
    "Therefore a max-weight IS must be either\n",
    "1. a max-weight IS of $G^\\prime$\n",
    "2. $v_n$ + a max-weight IS of $G^{\\prime\\prime}$\n",
    "\n",
    "This allows us to proceed recursively. The upshot is, out of all the exponential recursive calls, there are only $O(n)$ different subproblems, since the recursive calls only pluck out vertices from the left.\n",
    "\n",
    "This gives one algorithm,\n",
    "\n",
    "Let $G_i$ = G[0:i]\n",
    "\n",
    "Populate an array A, such that\n",
    "```\n",
    "A[i] = max-weight IS of G_i\n",
    "```\n",
    "\n",
    "Initialise \n",
    "```\n",
    "A[0] = 0, A[1] = w_1\n",
    "```\n",
    "\n",
    "Main loop\n",
    "```\n",
    "For i = 1, 2, ..., n:\n",
    "    A[i] = max(A[i-1], A[i-2] + w_i)\n",
    "```\n",
    "\n",
    "In order to return the Indepenant set itself, we could augment the data structure to contain the vertex information. However an alternative approach would be to reconstruct the optimal solution by tracing back through the filled in array A.\n",
    "\n",
    "Starting with the right most node,\n",
    "```\n",
    "i = n\n",
    "While i >= 1:\n",
    "    if A[i-1] >= A[i-2] + w_i(case 1):\n",
    "        do not include w_i\n",
    "        \n",
    "        i -= 1\n",
    "    else (case 2):\n",
    "        include w_i\n",
    "\n",
    "        i-=2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assingment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, 2\n",
    "Code up the greedy algorithm from the lectures on Huffman coding.\n",
    "\n",
    "The text file 'Week 3 huffman.txt' has the following format:\n",
    "\n",
    "[num of symbols]\n",
    "\n",
    "[weight of symbol 1]\n",
    "\n",
    "[weight of symbol 2]\n",
    "\n",
    "...\n",
    "\n",
    "Run the huffman coding algorithm from the lecture on this data set. \n",
    "\n",
    "What is the maximum length of a codeword in the resulting Huffman code?\n",
    "\n",
    "What is the minimum length codeword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('Week 3 huffman.txt') as f:\n",
    "        num_symbols = next(f)\n",
    "        return int(num_symbols), [int(x) for x in f]\n",
    "    \n",
    "num_symbols, weights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_utils import Heap\n",
    "\n",
    "def huffman(num_symbols: int, weights: list[int]):\n",
    "    char_heap = Heap[tuple[int]](type=\"min\")\n",
    "\n",
    "    char_list = [(x) for x in range(num_symbols)]\n",
    "    char_heap.build_heap(\n",
    "        char_list, \n",
    "        {char: weight for char, weight in zip(char_list, weights)}\n",
    "    )\n",
    "\n",
    "    while char_heap.size != 1:\n",
    "        min1, key1 = char_heap.extract_lead()\n",
    "        min2, key2 = char_heap.extract_lead()\n",
    "\n",
    "        char_heap.insert((min1, min2), key1+key2)\n",
    "    \n",
    "    final_tree = char_heap.extract_lead()\n",
    "\n",
    "    char_found = False\n",
    "    min_depth = None\n",
    "    max_depth = 0\n",
    "\n",
    "    def recurse(tree, depth):\n",
    "        nonlocal max_depth\n",
    "        nonlocal min_depth\n",
    "        nonlocal char_found\n",
    "\n",
    "        if depth > max_depth:\n",
    "            max_depth = depth\n",
    "\n",
    "        left, right = tree\n",
    "\n",
    "        if type(left) is tuple:\n",
    "            recurse(left, depth+1)\n",
    "        else:\n",
    "            if not char_found:\n",
    "                min_depth = depth\n",
    "                char_found = True\n",
    "\n",
    "        if type(right) is tuple:\n",
    "            recurse(right, depth+1)\n",
    "        else:\n",
    "            if not char_found:\n",
    "                min_depth = depth\n",
    "                char_found = True\n",
    "        \n",
    "    recurse(final_tree, 0)\n",
    "\n",
    "    return max_depth, min_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huffman(num_symbols, weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 \n",
    "\n",
    "Code up dynamic programming algorithm for computing a maximum weight indepedent set of a path graph.\n",
    "\n",
    "The file 'Week 3 mwis.txt' has the following format\n",
    "\n",
    "[num of vertices]\n",
    "\n",
    "[weigth of first vertex]\n",
    "\n",
    "[weight of second vertex]\n",
    "\n",
    "...\n",
    "\n",
    "The task is to run the dynamic programming algorithm and reconstruction procedure.\n",
    "\n",
    "Of the vertices\n",
    "$$\n",
    "1, 2, 3, 4, 17, 117, 517, 997\n",
    "$$\n",
    "\n",
    "Which ones belong to the maximum-weight independant set. \n",
    "\n",
    "Note that vertex 1 is the first vertex, there is no zeroth vertex.\n",
    "\n",
    "In the answering box, enter a 8-bit string where the $i^{th}$ bit should be 1 if the $i^{th}$ vertex of the of these 8 vertices is in the mwis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('Week 3 mwis.txt') as f:\n",
    "        num_vertices = next(f)\n",
    "        return int(num_vertices), [int(x) for x in f]\n",
    "\n",
    "num_vertices, weights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwis(num_vertices: int, weights: list[int]):\n",
    "    \n",
    "    memo = [0, weights[0]]\n",
    "    for i in range(1, num_vertices):\n",
    "        memo.append(max(memo[i], memo[i -1] + weights[i]))\n",
    "    \n",
    "    inde_set = set()\n",
    "    k = num_vertices\n",
    "\n",
    "    while k >= 1:\n",
    "        if memo[k-1] >= memo[k-2] + weights[k -1] :\n",
    "            k -= 1\n",
    "        else:\n",
    "            inde_set.add(k -1)\n",
    "            k -= 2\n",
    "\n",
    "    return inde_set\n",
    "\n",
    "inde_set = mwis(num_vertices, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10100110'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"1\" if x-1 in inde_set else \"0\" for x in [1, 2, 3, 4, 17, 117, 517, 997] ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
