{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruskal's MST Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the approach of including edges from the cheapest first, until a spanning tree is created, being careful to skip edges that create cycles.\n",
    "\n",
    "Psuedo-code \n",
    "```\n",
    "Kruskals():\n",
    "    Sort edges in order of increasing cost\n",
    "\n",
    "    T = {}\n",
    "\n",
    "    for i=1 to m:\n",
    "        if T union {i} has no cycles\n",
    "            add i to T\n",
    "    \n",
    "    return T\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proofs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that the output is a spanning tree\n",
    "\n",
    "Let $T^*$ be the output of Kruskal's algorithm. By definition $T^*$ has no cycles. It stands to show that $T^*$ is connected.\n",
    "\n",
    "Fix a cut $(A, B)$. Since the input graph is connected, at least one if its edges crosses $(A, B)$. \n",
    "\n",
    "We know that Kruskals algorithm considers all edges at least once. \n",
    "\n",
    "By the double crossing lemma, the first time Kruskals algorithm encounters an edge that crosses $(A,B)$ it can not be part of an existing cycle, since there must be at least two crossing edges for a cycle to exist.\n",
    "\n",
    "Therefore, the first edge Kruskal's algorithm encounters will be included. \n",
    "\n",
    "Therefore, there are no cuts with no crossing edges, and $T^*$ is connected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that the spanning tree is minimal\n",
    "\n",
    "We will show that every edge of $T^*$ satsifies the minimim cut property.\n",
    "\n",
    "Consider an interation where the algorithm includes the edge $(u, v)$ to the set $T$\n",
    "\n",
    "Since $T \\cup (u, v)$ has no cycles, there does not currently exist a path between $u$ and $v$ in $T$.\n",
    "\n",
    "Therefore there must exist an empty cut $(A, B)$ with $u$ and $v$ in seperate parts.\n",
    "\n",
    "Since Kruskal's algorihtm iterates over sorted edges, the edge $(u, v)$ is garunteed to be the cheapest edge across the $(A, B)$ cut. If there were a cheaper such edge, this edge would have already been considered at an earlier iteration of the algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straighforward Implementation\n",
    "\n",
    "Sorting the edges will take $O(m\\log{m}) = O(m\\log{n})$ time.\n",
    "$$\n",
    "m = O(n^2) \\\\\n",
    "\\log{m} \\leq 2\\log{n} + c \\\\\n",
    "\\log{m} = O(\\log{n})\n",
    "$$\n",
    "\n",
    "Iterating over the edges takes $O(m)$ time, however checking for cycles will take $O(n)$ time. \n",
    "\n",
    "In order to check for a cycle, we can carry out DFS or BFS which runs in linear time.\n",
    "\n",
    "This gives an overal running time of\n",
    "$$\n",
    "O(m\\log{n}) + O(mn) = O(mn)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union-Find\n",
    "\n",
    "This data structure hopefully allows constant time cycle checking.\n",
    "\n",
    "A Union-Find data strucutre maintains a parition of a set of objects and supports two operations\n",
    "\n",
    "1. Find $x$ : -> name of the group that $x$ belongs to\n",
    "2. Union $g_1$, $g_2$ : -> fuse the two groups into one\n",
    "\n",
    "To implement the Union-Find,\n",
    "\n",
    "1. maintain one linked structure per connected component \n",
    "2. each connected component has an arbitrarily chosen leader\n",
    "3. each vertex contains a pointer to the leader of its component\n",
    "\n",
    "To check if an edge $(u, v)$ will create a cycle, check if both nodes point to the same leader.\n",
    "$$\n",
    "\\text{Find}(u) = \\text{Find}(v) \\iff \\text{cycle exists}\n",
    "$$\n",
    "By looking up pointers this runs in $O(1)$ time.\n",
    "\n",
    "In order to update leader points when performing a Union,\n",
    "\n",
    "1. keep the leader with more children as the new leader\n",
    "2. rewire the smaller leaders children.\n",
    "\n",
    "Globally, any one node will be updated $O(\\log{n})$ time, each rewire costs $O(n)$, resulting in $O(n\\log{n})$ overall rewiring cost.\n",
    "\n",
    "Overall, this gives\n",
    "1. $O(m\\log{n})$ time for sorting\n",
    "2. $O(m) \\times O(1)$ time for cycle checks\n",
    "3. $O(n\\log{n})$ time for overall rewires\n",
    "\n",
    "Which has overall $O(m\\log{n})$ running time.\n",
    "\n",
    "There is another way to do this,\n",
    "1. When carrying out $\\text{Find}(x)$ follow leader's recursively\n",
    "2. When carrying out $\\text{Union}(g_1, g_2)$ only rewire leaders.\n",
    "\n",
    "This would increase the running time of $\\text{Find}$ to $O(\\log{n})$, and decrease the running time of $\\text{Union}$ to $O(1)$. Overall,\n",
    "\n",
    "2. $O(m) \\times O(\\log{n})$ time for cycle checks\n",
    "3. $O(m) \\times O(1)$ time for rewires\n",
    "\n",
    "Which has the same overall $O(m\\log{n})$ running time.\n",
    "\n",
    "I think the other implementation should be faster but this is yet to be checked."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of the Art MST\n",
    "\n",
    "There is an [$O(m)$ randomized algorithm](https://cs.brown.edu/research/pubs/pdfs/1995/Karger-1995-RLT.pdf)! It is unknown is there is a determinstic linear time algorithm.\n",
    "\n",
    "There is a almost linear [$O(m\\alpha(n))$ determmistic algorihtm](https://www.cs.princeton.edu/~chazelle/pubs/mst.pdf). Where $\\alpha(n)$ is the inverse [ackerman function](https://en.wikipedia.org/wiki/Ackermann_function). \n",
    "\n",
    "The inverse ackerman function grows SUPER slowly, in fact its grows much slower than\n",
    "$$\n",
    "\\log^*{n} := \n",
    "\\begin{cases}\n",
    "0 & \\text{if} \\; n \\leq 1 \\\\\n",
    "1 + \\log^*(\\log{n}) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "Which simply put is the \"inverse tetration\" function.\n",
    "\n",
    "The ackerman function can be stated\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&A(0, n) &&= \\quad n+1 \\\\\n",
    "&A(m+1, 0) &&= \\quad A(m, 1) \\\\\n",
    "&A(m+1, n+1) &&= \\quad A(m, A(m+1, n))\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Open Questions\n",
    "\n",
    "- There are no simple (undergraduate level) randomised linear time algorithms. It is sufficient to find a MST verification algorithm to deal with a randomised algorithm. \n",
    "\n",
    "- Is there a determinised linear time algorithm?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $n$ points in some space, we want to classify them into \"coherent groups\"\n",
    "\n",
    "We provide a distance metric $d(q,p)$ between each point pair that is symmetric, ie,\n",
    "$$\n",
    "d(p, q) = d(q, p)\n",
    "$$.\n",
    "\n",
    "We aim to group \"nearby\" points by minimising the distance metric.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Spacing k-Clusterings\n",
    "\n",
    "Assume that we know that there are $k$ clusters to look for.\n",
    "\n",
    "Label two points $p, q$ as separted if they're assigned to different clusters.\n",
    "\n",
    "Define the spacing of a k-clustering\n",
    "$$\n",
    "\\min_{\\text{seperated} \\; p, q}{d(p, q)}\n",
    "$$\n",
    "In other words, the closest two seperated points.\n",
    "\n",
    "Given a distance metric $d$ and some number of clusters $k$ we seek to compute a clustering that has the maximum possible spacing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Greedy Algorithm\n",
    "\n",
    "Starting with all points in their own clusters, \n",
    "1. Find the closest pair of seperated points,\n",
    "2. Fuse these two clusters into one \n",
    "3. If this gives the correct number of clusters, return\n",
    "3. Else Repeat\n",
    "\n",
    "This is the same as Kruskals algorithm!! This is known as Single-link clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corectness Proof\n",
    "\n",
    "Let the greedy clustering be\n",
    "$$\n",
    "C_1, C_2, \\cdots, C_k \n",
    "$$\n",
    "\n",
    "Let an arbitrary clustering be\n",
    "$$\n",
    "\\hat{C}_1, \\hat{C}_2, \\cdots, \\hat{C}_k\n",
    "$$\n",
    "\n",
    "Define $S$ to be the spacing of a clustering\n",
    "$$\n",
    "S(C_1, C_2, \\cdots, C_k) = \\text{spacing of the clustering}\n",
    "$$\n",
    "\n",
    "Let $s^*$ be the optimal spacing\n",
    "\n",
    "We seek to show that\n",
    "$$\n",
    "S(\\hat{C}_1, \\hat{C}_2, \\cdots, \\hat{C}_k) \\leq s^*\n",
    "$$\n",
    "\n",
    "Case 1:\n",
    "\n",
    "If $\\hat{C}_i \\sim C_i$ by renaming and re-ordering, then they have the same spacing.\n",
    "\n",
    "Case 2:\n",
    "\n",
    "Otherwise, we can find a pair of points $p,q$ such that \n",
    "1. $p, q \\in C_i$\n",
    "2. $p \\in \\hat{C_i}$ while $q \\in \\hat{C_j}$\n",
    "\n",
    "The property of the greedy algorithm indicates that if two points $x, y$ have been directly merged, then\n",
    "$$\n",
    "d(x, y) \\leq s^*\n",
    "$$\n",
    "\n",
    "Furthermore, the distances between merged pairs in order, is always increasing.\n",
    "\n",
    "Trivial case:\n",
    "\n",
    "$p, q$ were directly merged by the algorithm. This would imply that\n",
    "$$\n",
    "d(p, q) \\leq s^*\n",
    "$$\n",
    "Since $p$ and $q$ lie in seperate clusters in the arbitrary clustering, then\n",
    "$$\n",
    "S(\\hat{C}_1, \\hat{C}_2, \\cdots, \\hat{C}_k) \\leq d(p, q) \\leq s^*\n",
    "$$\n",
    "\n",
    "Tricky case:\n",
    "\n",
    "$p, q$ were merged through multiple direct merges.\n",
    "\n",
    "Let \n",
    "$$\n",
    "p, a_1, a_2, \\cdots, a_r, q\n",
    "$$\n",
    "be the path of direct greedy merges connecting $p$ and $q$\n",
    "\n",
    "Since $p \\in \\hat{C}_i$ and $q \\in \\hat{C}_j$ there exists a consecuitive pair of nodes $a_j, a_{j+1}$ that bridges the gap.\n",
    "\n",
    "Since the consecuitive nodes were directly merged,\n",
    "$$\n",
    "S(\\hat{C}_1, \\hat{C}_2, \\cdots, \\hat{C}_k) \\leq d(a_j, a_{j+1}) \\leq s^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union-Find in depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Unions\n",
    "\n",
    "This is what I wrote about earlier, where we only rewire leaders during a union.\n",
    "\n",
    "We consider the array representation of the parent relationships. Let $A[i]$ denote the name of $i$'s parent.\n",
    "\n",
    "Consider the example where objects $1$ and $2$ belong to the same group, and objects $3$, $4$, $5$ belong to a second group.\n",
    "$$\n",
    "\\fbox{1}\\fbox{1}\\fbox{4}\\fbox{4}\\fbox{4} \\\\[10pt]\n",
    "\\rightarrow \\quad \\fbox{1}\\fbox{1}\\fbox{1}\\fbox{4}\\fbox{4}\n",
    "$$\n",
    "\n",
    "In general,\n",
    "\n",
    "Define a root as a node $x$ where,\n",
    "$$\n",
    "\\text{parent}[x] = x\n",
    "$$\n",
    "\n",
    "Initialise: for all $x$, $\\text{parent}[x] := x$\n",
    "$$\n",
    "\\text{Find}(x) : \\text{traverse parent pointers until you hit a root} \\\\[10pt]\n",
    "\\begin{aligned}\n",
    "    \\text{Union}(x,y) : \\;& s_1 = \\text{Find}(x) \\\\\n",
    "    & s_2 = \\text{Find}(y) \\\\\n",
    "    & \\text{reset parent of one of} \\; s_2 , s_1 \\; \\text{to the other}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "As we allow the parent graph depth to increase, we will need to be careful about how we perform unions such that our tree depth is not $O(n)$ but rather $O(\\log{n})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union by Rank Optimisation\n",
    "\n",
    "For each object $x \\in X$ maintain a field $\\text{rank}[x]$ where\n",
    "$$\n",
    "\\text{rank}[x] = \\text{maximum number of hops from a leaf to} \\; x\n",
    "$$\n",
    "\n",
    "Using the rank, we can be careful to always maintain the leader with higher rank as the top most node.\n",
    "\n",
    "```\n",
    "Union(x,y):\n",
    "    s1 = Find(x)\n",
    "    s2 = Find(x)\n",
    "\n",
    "    if rank[s1] > rank[s2]:\n",
    "        parent[s2] = s1\n",
    "\n",
    "    else:\n",
    "        parent[s1] = s2\n",
    "\n",
    "```\n",
    "\n",
    "Properties of rank:\n",
    "\n",
    "1. for all objects $x$, $\\text{rank}[x]$ increases monotonically\n",
    "2. only the ranks of root can increase $\\implies$ once $x$ is not a root, $\\text{rank}[x]$ is fixed\n",
    "3. ranks strictly increasing along the path to the root \n",
    "\n",
    "#### Rank Lemma:\n",
    "\n",
    "Consider an arbitrary sequence of $\\text{Union}$ and $\\text{Find}$ operations.\n",
    "$$\n",
    "\\forall r \\in \\{0, 1, 2, \\cdots\\}\n",
    "$$\n",
    "there are at most\n",
    "$$\n",
    "\\frac{n}{2^r}\n",
    "$$\n",
    "objects with rank $r$.\n",
    "\n",
    "Collorary:\n",
    "$$\n",
    "\\forall x, \\quad \\text{rank}[x] \\leq \\log_2{n}\n",
    "$$\n",
    "Therefore the wost-case running time of $\\text{Find}$ and $\\text{Union}$ is\n",
    "$$\n",
    "O(\\log{n})\n",
    "$$\n",
    "\n",
    "#### Proof of Rank Lemma:\n",
    "\n",
    "Claim 1:\n",
    "\n",
    "If $x$, $y$ have the same rank r, then their subtrees are disjoint.\n",
    "\n",
    "Claim 2:\n",
    "\n",
    "The subtree of a rank r object has size $\\geq 2^r$\n",
    "\n",
    "With Claim 1 and Claim 2, the rank lemma is implied.\n",
    "\n",
    "Proof of claim 1 (by contrapositive):\n",
    "\n",
    "Suppose subtrees of $x$, $y$ have object $z$ in common.\n",
    "$$\n",
    "\\exists \\text{paths} \\quad z \\rightarrow x, \\; z \\rightarrow y \n",
    "$$\n",
    "\n",
    "Since the these trees can only have one parent pointer, this implies that both $x$ and $y$ lie on the same path to the parent pointer. \n",
    "\n",
    "This implies that one of $x$ or $y$ is an ancestor of the other.\n",
    "\n",
    "This implies that the rank of $x$ cannot be the same as $y$. As the ancestor must have a strictly higher rank.\n",
    "\n",
    "Proof of Claim 2 (By Induction):\n",
    "\n",
    "Base Case: initially all ranks =0, subtree size = 1\n",
    "\n",
    "Inductive Hypothesis:\n",
    "$$\n",
    "\\text{subtree size} \\geq 2^r\n",
    "$$\n",
    "\n",
    "Inductive step:\n",
    "\n",
    "$\\text{Union}(x, y)$ performs\n",
    "$$\n",
    "s_1 = \\text{Find}(x) \\quad s_2 = \\text{Find}(y)\n",
    "$$\n",
    "\n",
    "The ranks of $s_1$ and $s_2$ will only change when,\n",
    "$$\n",
    "\\text{rank}[s_1] = \\text{rank}[s_2]\n",
    "$$\n",
    "\n",
    "In which case, the rank of $s_2$ will increase by 1. Furthermore, the subtree size will increase to\n",
    "$$\n",
    "s_2 \\; \\text{old subtree size} + s_2 \\; \\text{old subtree size} \\\\[10pt]\n",
    "\\implies \\text{subtree of rank}[s_2] \\geq 2^r + 2^r = 2^{r+1}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Compression Optimisation\n",
    "\n",
    "This acts ontop of union by rank. The idea, is to remap parents once a $\\text{Find}$ is invoked once! This saves the work and long paths only need to be traversed once!\n",
    "\n",
    "The remapping only adds a constant work factor to each $\\text{Find}$. Furthermore, each subsequent $\\text{Find}$ operation would then take $O(1)$ time.\n",
    "\n",
    "#### Interacting with Rank\n",
    "\n",
    "Ranks can be maintained in the same way.\n",
    "1. Initialised to 0\n",
    "2. in $\\text{Union}$, new root := old root with bigger rank\n",
    "3. If the two ranks are equal, increment new rank\n",
    "\n",
    "Do not change ranks after applying path compression. Path Compression does not change the Rank Lemma. Further,\n",
    "$$\n",
    "\\text{rank}[\\text{parent}[x]] > \\text{rank}[x]\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopcroft-Ullman Theorem\n",
    "\n",
    "Consider a Union-Find data structure implemented with\n",
    "1. Union by Rank\n",
    "2. Path Compression\n",
    "\n",
    "Then $m$ $\\text{Union}$ and $\\text{Find}$ operations will take,\n",
    "$$\n",
    "O(m \\log^*{n})\n",
    "$$\n",
    "time. Inverse tetration!!\n",
    "\n",
    "#### Proof of Hopcroft-Ullman Theorem\n",
    "\n",
    "We seek to measure the improvement over subsequent $\\text{Find}$ and $\\text{Union}$ operations.\n",
    "\n",
    "Consider a non-root object $x$. We can define a measure of progress for $x$ as\n",
    "$$\n",
    "\\text{rank}[\\text{parent}[x]] - \\text{rank}[x]\n",
    "$$\n",
    "\n",
    "The difference allows us to get a handle on the worst case number of parent hops, before landing at the parent. A small difference indicates that the parent pointer moves slowly up the rank space, while a larger difference indicates making more progress through to a root.\n",
    "\n",
    "Applying path compression will improve this progress measure. Since, if $x$ has old parent $p$ and new parent $p^\\prime$.\n",
    "$$\n",
    "\\text{rank}[p^\\prime] > \\text{rank}[p]\n",
    "$$\n",
    "\n",
    "Rank blocks:\n",
    "$$\n",
    "\\{0\\}, \\; \\{1\\}, \\; \\{2, 3, 4\\}, \\; \\{5, \\cdots, 2^4\\}, \\; \\{17, \\cdots, 2^16\\}, \\cdots\n",
    "$$\n",
    "In general define a rank block as a set of numbers of in the range\n",
    "$$\n",
    "\\{k, \\cdots 2^k\\}\n",
    "$$\n",
    "Where $k$ is the largest number of the previous rank block.\n",
    "\n",
    "In general for $n$ elements, there will be\n",
    "$$\n",
    "O(\\log^*{n})\n",
    "$$\n",
    "rank blocks.\n",
    "\n",
    "We will use rank blocks to asses the gap between the rank a non root node and its parent. Generally, if the two ranks are in a different rank block, we think of this as \"fast progress\".\n",
    "\n",
    "Lets call a object $x$ \"good\" if\n",
    "1. $x$ or $x$ parent is a root\n",
    "2. $\\text{rank}[\\text{parent}[x]]$ is in a larger rank block than $x$\n",
    "\n",
    "Otherwise $x$ is \"bad\"\n",
    "\n",
    "If we land on a good node, $\\text{Find}$ would only encounter\n",
    "$$\n",
    "2 + \\text{\\# of rank blocks} = O(\\log^*{n})\n",
    "$$,\n",
    "since each hop must take the parent up to the next rank block.\n",
    "\n",
    "Total work done during $m$ operations =\n",
    "$$\n",
    "O(m \\log^*{n}) + \\; \\text{total \\# of visits to bad nodes}\n",
    "$$\n",
    "\n",
    "Consider a rank block $\\{k+1, k+2, \\cdots, 2^k\\}$. \n",
    "\n",
    "When a bad node $x$ is visited, it's parent is changed to one with a strictly larger rank. Further, note that since $x$ is bad, $x$ is neither a root node, nor a direct child of a root node.\n",
    "\n",
    "Since the rank of the parent is increased during path compression, it's parent can be changed a maximum of $2^k$ times, before $x$ becomes a good node (forevermore).\n",
    "$$\n",
    "\\text{\\# of times a bad node can be visited} \\leq 2^k\n",
    "$$\n",
    "\n",
    "By the rank lemma, the total number of objects $x$ with final rank in this rank block is\n",
    "$$\n",
    "\\sum_{i+k_1}^{2^k}{\\frac{n}{2^i}} \\leq \\frac{n}{2^k}\n",
    "$$\n",
    "\n",
    "Therefore there are less than $n$ visits to bad nodes in each rank block\n",
    "\n",
    "Therefore, since there are only $O(\\log^*{n})$ rank blocks, the total work done on bad nodes is \n",
    "$$\n",
    "O(n\\log^*{n})\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarjan's Bound\n",
    "\n",
    "For Union-Find data structure implemented with Union by Rank and path compression, $m$ $\\text{Union}$ and $\\text{Find}$ operations will take \n",
    "$$\n",
    "O(m\\alpha(n))\n",
    "$$\n",
    "Where $\\alpha(n)$ is the inverse ackerman function\n",
    "\n",
    "#### The Ackerman Function\n",
    "\n",
    "Define $A_k(r)$ for all $k \\geq 0 $, $r \\geq 1$, $k, r \\in \\mathbb{Z}$\n",
    "$$\n",
    "A_0(r) = r + 1 \n",
    "$$\n",
    "for $k, r \\geq 1$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A_k(r) &= \\; \\text{apply} \\; A_k \\; r \\; \\text{times to} \\; r \\\\\n",
    "& = \\underbrace{(A_{k-1} \\circ A_{k-1} \\circ \\cdots \\circ A_{k-1})}_{r \\; \\text{times}}(r)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Some initial cases,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A_1(r) &= \\underbrace{(A_{0} \\circ A_{0} \\circ \\cdots \\circ A_{0})}_{r \\; \\text{times}}(r) \\\\\n",
    "&=\\underbrace{(\\cdots(((r +1) +1) +1) \\cdots ) +1}_{r \\; \\text{times}} \\\\\n",
    "&= 2r \\\\[20pt]\n",
    "\n",
    "A_2(r) &= \\underbrace{(A_{1} \\circ A_{1} \\circ \\cdots \\circ A_{1})}_{r \\; \\text{times}}(r) \\\\\n",
    "&=\\underbrace{2 \\times (\\cdots(2 \\times (2 \\times (r))) \\cdots )}_{r \\; \\text{times}} \\\\\n",
    "&= r2^r \\\\[20pt]\n",
    "\n",
    "A_3(r) &= \\underbrace{(A_{2} \\circ A_{2} \\circ \\cdots \\circ A_{2})}_{r \\; \\text{times}}(r) \\\\\n",
    "&> 2^{2^{2^{\\cdot^{\\cdot^{\\cdot^{r}}}}}} \\\\[20pt]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### The Inverse Ackerman Function\n",
    "\n",
    "For our cases, we define the inverse ackerman function for every $n\\geq 4$\n",
    "$$\n",
    "\\alpha(n) = \\text{minimum value of} \\; k \\; \\text{such that} \\; A_k(2) \\geq n\n",
    "$$\n",
    "\n",
    "For the first few cases,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{for} \\; n = 4, \\\\\n",
    "&&\\alpha(n) = 1 \\\\\n",
    "&\\text{for} \\; n = 5, 6, 7, 8 \\\\\n",
    "&&\\alpha(n) = 2 \\\\\n",
    "&\\text{for} \\; n = 9, 10, \\cdots, 2048 \\\\\n",
    "&&\\alpha(n) = 3\\\\\n",
    "&\\text{for} \\; n = 2048, 2049, \\cdots,  \\approx{^{2048}2}\\\\\n",
    "&&\\alpha(n) = 4\\\\\n",
    "\\vdots\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### Proof of Tarjan's Bound\n",
    "\n",
    "We will proceed similarly to the Hopcroft Ullman Theorem. However, instead of arguing that the rank of the parent increases by at minimum 1, we will seek to show that the rank of a new parent is typically much larger than the rank of the old parent.\n",
    "\n",
    "Consider a non-root object $x$, define\n",
    "$$\n",
    "\\delta(x) = \\max{k} \\; \\text{such that} \\;{(\\text{rank}[\\text{parent}[x]] \\geq A_k(\\text{rank}[x]))}\n",
    "$$\n",
    "\n",
    "Some examples,\n",
    "$$\n",
    "\\text{rank}[\\text{parent}[x]] \\geq \\text{rank}[x] + 1 \\iff \\delta(x) \\geq 0 \\\\[10pt]\n",
    "\n",
    "\\text{rank}[\\text{parent}[x]] \\geq 2 \\times \\text{rank}[x] \\iff \\delta(x) \\geq 1 \\\\[10pt]\n",
    "\n",
    "\\text{rank}[\\text{parent}[x]] \\geq \\text{rank}[x] \\times 2^{\\text{rank}[x]} \\iff \\delta(x) \\geq 2 \\\\[10pt]\n",
    "$$\n",
    "\n",
    "The larger the gap between the rank a non-roots object and its parent, the larger $\\delta(x)$ becomes. Further,\n",
    "$$\n",
    "\\text{Since} \\; A_{\\alpha(n)}(2) \\geq n \\\\[10pt]\n",
    "\\forall x, \\; \\text{rank}[x] \\geq 2 \\\\\n",
    "\\implies \\delta(x) \\leq \\alpha(n) \n",
    "$$\n",
    "\n",
    "An object $x$ is defined to be \"bad\" if all of the following are true:\n",
    "1. $x$ is not a root\n",
    "2. $\\text{parent}[x]$ is not a root\n",
    "3. $\\text{rank}[x] \\geq 2$\n",
    "4. $x$ has an ancestor $y$ with $\\delta(y) = \\delta(x)$\n",
    "\n",
    "Otherwise $x$ is good\n",
    "\n",
    "Lemma: For any objecet-root path there are at most $O(\\alpha(n))$ good objects.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{\\# of good nodes} &= 1 \\; \\text{root} \\\\\n",
    "&+1 \\; \\text{child of root} \\\\\n",
    "&+1 \\; \\text{of rank} \\; 0 \\\\\n",
    "&+1 \\; \\text{of rank} \\; 1 \\\\\n",
    "&\\quad \\text{for each} \\; k = 0, 1, 2, \\cdots, \\alpha(n): \\\\\n",
    "& \\quad \\quad +1 \\; \\text{object} \\\\\n",
    "&= O(\\alpha(n))\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For the last statement, we consider all objects in the path that have\n",
    "$$\n",
    "\\delta(x) = k\n",
    "$$\n",
    "There can be at most one, such good object. This will be the object heighest in the tree. All other objects will have the same $\\delta$ value and hence are bad objects as they will have at least this one good object as an ancestor object.\n",
    "\n",
    "In general, the total work for $m$ operations will be\n",
    "$$\n",
    "= \\underbrace{O(m\\alpha(n))}_{\\text{visits to good objects}} + \\text{total \\# of visits to bad objects}\n",
    "$$\n",
    "\n",
    "Suppose a $\\text{Find}$ operation visits a bad object $x$.\n",
    "$$\n",
    "\\cdots \\rightarrow \\fbox{$x$} \\rightarrow \\fbox{$p$} \\rightarrow \\cdots \\rightarrow \\fbox{$y$} \\rightarrow \\fbox{$p^\\prime$} \\rightarrow \\cdots\n",
    "$$\n",
    "Where,\n",
    "$$\n",
    "\\delta(x) = k \\\\\n",
    "\\delta(y) = k\n",
    "$$\n",
    "After applying path compression, $x$ new parent will be $p^\\prime$ or higher.\n",
    "\n",
    "Let $p^*$ be the new parent of $x$ at the root of tree. Applying path compression\n",
    "$$\n",
    "\\implies \\text{rank}[p^*] \\geq \\text{rank}[p^\\prime]\\geq A_k(\\text{rank}[y]) \\geq A_k(\\text{rank}[p])\n",
    "$$\n",
    "Therefore we deduce that path compression applies the $A_k$ function to the rank of an objects function.\n",
    "\n",
    "If $r = \\text{rank}[x]$ and $r \\geq 2$, then after $r$ such pointer updates we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{rank}[\\text{parent}[x]] &\\geq \\underbrace{(A_{k} \\circ A_{k} \\circ \\cdots \\circ A_{k})}_{r \\; \\text{times}}(r) \\\\\n",
    "& = A_{k+1}(r)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore after every $r$ visits to a bad $x$, the value of $\\delta(x)$ must increment.\n",
    "$$\n",
    "\\implies \\text{\\# of visits to bad} \\; x \\leq r \\times \\alpha(n)\n",
    "$$\n",
    "\n",
    "Therefore the total amount of work done on bad objects\n",
    "$$\n",
    "\\leq \\sum_{\\text{objects} \\; x}{\\text{rank}[x]} \\times \\alpha(n)\\\\[10pt]\n",
    "= \\alpha(n) \\sum_{r \\geq 0}{r \\times \\text{\\# objects with rank} \\; r} \\\\[10pt]\n",
    "= \\alpha(n) \\sum_{r \\geq 0}{r \\times \\frac{n}{2^r}} \\\\[10pt]\n",
    "= n\\alpha(n) \\sum_{r \\geq 0}{\\frac{r}{2^r}}\n",
    "$$\n",
    "We can evaluate the sum\n",
    "\n",
    "Note that by geometric series,\n",
    "$$\n",
    "\\sum_{r \\geq 0}{\\frac{a}{2^r}} = \\frac{a}{1 - \\frac{1}{2}}\n",
    "$$\n",
    "Then,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{r \\geq 0}{\\frac{r}{2^r}} &= 0 +\\frac{1}{2^1} +\\frac{2}{2^2} +\\frac{3}{2^3} +\\frac{4}{2^4} + \\frac{5}{2^5} + \\cdots \\\\[10pt]\n",
    "&\\begin{alignat*}{5}\n",
    "&=\\frac{1}{2^1} &+\\frac{1}{2^2} &+\\frac{1}{2^3} &+\\frac{1}{2^4} &+\\frac{1}{2^5} + \\cdots \\\\[10pt]\n",
    "& &+\\frac{1}{2^2} &+\\frac{1}{2^3} &+\\frac{1}{2^4} &+\\frac{1}{2^5} + \\cdots \\\\[10pt]\n",
    "& & &+\\frac{1}{2^3} &+\\frac{1}{2^4} &+\\frac{1}{2^5} + \\cdots \\\\[10pt]\n",
    "& & & &+\\frac{1}{2^4} &+\\frac{1}{2^5} + \\cdots \\\\[10pt]\n",
    "& & & & &+\\frac{1}{2^5} + \\cdots \\\\[10pt]\n",
    "& & & & &\\quad \\quad \\vdots\n",
    "\\end{alignat*} \\\\[20pt]\n",
    "&= \\sum_{i \\geq 1}{\\sum_{r \\geq i}{\\frac{1}{2^r}}} \\\\\n",
    "&= \\sum_{i \\geq 1}{\\left(\\frac{1}{2^i} \\times \\frac{1}{1-\\frac{1}{2}}\\right)} \\\\\n",
    "&= 2 \\times \\sum_{i \\geq 1}{\\frac{1}{2^i}} \\\\\n",
    "& = 2 \\times \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = 2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore the work done on bad nodes will be\n",
    "$$\n",
    "O(n\\alpha(n))\n",
    "$$\n",
    "Making the overall work\n",
    "$$\n",
    "O((m + n )\\alpha(n)) = O(m \\alpha(n))\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
