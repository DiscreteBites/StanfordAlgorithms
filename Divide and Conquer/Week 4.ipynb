{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Algorithms\n",
    "\n",
    "Select the $i^{th}$ largest element in an unsorted array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Selection\n",
    "\n",
    "Using the QuickSort algorithm with randomly chosen pivots, we are able to recurse on just the desired half of the array that contains the $i^{th}$ largest element by \"throwing away\" the other part of the array."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of choosing a random pivot, we \n",
    "\n",
    "1. Break the array into groups of 5, sort each group\n",
    "2. find the medians of each group \n",
    "3. Recurse on the list of medians to get the median"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimimum Graph Cuts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging of random nodes can be shown to be correct with probability\n",
    "\n",
    "$$\n",
    "\\frac{2}{n(n-1)}\n",
    "$$\n",
    "\n",
    "Then doing repeating the procedure $n^{2}\\log{n}$ times is able to turn the probability of one of the trails finding the minimum cut to $\\frac{1}{n}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Theory Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Prove that the worst-case expected running time of every randomized comparison-based sorting algorithm is $\\Omega(n\\log{n})$. (Here the worst-case is over inputs, and the expectation is over the random coin flips made by the algorithm.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an array of length $n$, there are at most $n!$ different permutations.\n",
    "\n",
    "For any randomised comparison-based sorting algorithm, making $m$ comparisons, to be correct, it needs to define a map from the space of input permutations to the single sorted case.\n",
    "\n",
    "Since the comparisons return binary values, we can map the associated binary bit string of comparisons made to each of the $n!$ possible inputs. Since these inputs are unique, the bit string of comparisons needs to also be unique.\n",
    "\n",
    "This mapping can be shown to be a bijection as each bit string specifies steps that turn the input array into the sorted array, and step can be followed in reverse to turn the sorted array back into each bit string. \n",
    "\n",
    "There are $2^m$ possible bit strings. Therefore, it is required that \n",
    "$$\n",
    "2^m \\leq n!\n",
    "$$\n",
    "Taking a weak upperbound for $n!$\n",
    "$$\n",
    "2^m \\leq n! \\leq n^n \\\\[10pt]\n",
    "m\\ln{2} \\leq n\\ln{n} \\\\[10pt]\n",
    "m = \\Omega{n\\ln{n}} \n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Suppose we modify the deterministic linear-time selection algorithm by grouping the elements into groups of 7, rather than groups of 5. (Use the \"median-of-medians\" as the pivot, as before.) Does the algorithm still run in $O(n)$ time? What if we use groups of 3?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general recurrence takes the form\n",
    "$$\n",
    "T(n) \\leq O(n) + T\\left(\\frac{n}{a}\\right) + T(k)\n",
    "$$\n",
    "\n",
    "In order to compute the size of $k$, we can employ a similar argument to that when used for the groups of 5 case. Consider groups of some size $a$, for simplicity, lets assume that the size of the array $n$ is a multiple of $a$. Then, the median of medians of these $\\frac{n}{a}$ groups of size $a$ will be greater than, \n",
    "$$\n",
    "\\frac{a}{2} \\times \\frac{1}{2} \\times \\frac{n}{a} = \\frac{n}{4}\n",
    "$$\n",
    "\n",
    "Therefore we can conclude that irresepctive of the size of $a$, taking a median of medians will split the group into $\\frac{n}{4}$ and $\\frac{3n}{4}$. This means that \n",
    "$$\n",
    "k = \\frac{3}{4} n\n",
    "$$\n",
    "\n",
    "And the argument still follows to give a $O(n)$ time, just with a different coeffecient."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Given an array of $n$ distinct (but unsorted) elements $x_1, x_2, \\ldots , x_n$ with positive weights $w_1, w_2, \\ldots , w_3$ such that $\\sum_{i=1}^{n} w_i = W$, a weighted median is an element $x_k$ for which the total weight of all elements with value less than $x_k$ is at most $W/2$, and also the total weight of elements with value larger than $x_k$ is at most $W/2$. Observe that there are at most two weighted medians. Show how to compute all weighted medians in $O(n)$ worst case time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To show that there are at most two weighted medians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a weighted median $x_k$ we have,\n",
    "$$\n",
    "\\sum_{x_i < x_k}{w_i} \\leq \\frac{W}{2} \\quad \\text{and} \\quad \\sum_{x_i > x_k}{w_i} \\leq \\frac{W}{2} \\\\\n",
    "$$\n",
    "\n",
    "Consider a particular weighted mean $x_k$ with weight $w_k$. Since\n",
    "$$\n",
    "\\left(\\sum_{x_i < x_k}{w_i} \\right) + w_k + \\left(\\sum_{x_i > x_k}{w_i}\\right) = W \\\\[10pt]\n",
    "\\left(\\sum_{x_i < x_k}{w_i} \\right) + w_k \\geq \\frac{W}{2} \\quad \\text{and} \\quad \\left(\\sum_{x_i > x_k}{w_i} \\right) + w_k \\geq \\frac{W}{2}\n",
    "$$\n",
    "\n",
    "Now consider that there is another weighted median $x_t$ with weight $w_t$. WLOG, assume that $x_t > x_k$. This would mean that we require,\n",
    "$$\n",
    "\\sum_{x_i < x_t}{w_i} = \\left(\\sum_{x_i < x_k}{w_i}\\right) + w_k + \\left(\\sum_{x_k < x_i < x_t}{w_i}\\right) \\leq \\frac{W}{2}\n",
    "$$\n",
    "\n",
    "However, this can only hold if \n",
    "$$\n",
    "\\left(\\sum_{x_i < x_k}{w_i} \\right) + w_k = \\sum_{x_i < x_t}{w_i} = \\frac{W}{2} \\quad \\text{and} \\quad \\sum_{x_k < x_i < x_t}{w_i} = 0\n",
    "$$\n",
    "\n",
    "Since the weights have to be positive, the only way for the sum of weights between $w_k$ and $w_t$ to be zero is for there to be no weights between the two, that is, $t = k+1$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the weighted medians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the template for the RSelect and DSelect algorithm.\n",
    "\n",
    "Rough outline,\n",
    "1. Choose a pivot\n",
    "2. QuickSort step $O(n)$\n",
    "3. find the left and right weighted sums $O(n)$.\n",
    "\n",
    "    if sum $< W/2$ and sum $ + w_{pivot} > W/2$, then we've found the only median\n",
    "\n",
    "    if sum = $W/2$ and sum $ + w_{pivot} = W/2$ or vice versa, then we've found two consecutive medians\n",
    "\n",
    "4. Recurse on one half of the problem where sum $> W/2$ remembering the necessary other sum so we don't need to recompute this.\n",
    "\n",
    "I think we just use the same median of medains method from DSelect to choose a pivot as this garuntees a 25 - 75 split between the values of the correcet sort of $x_i$. This is enough to ensure that when we recurse, the problem size must decrease to at least 75% of the previous size which was enough to garuntee $O(n)$ time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "We showed in an optional video lecture that every undirected graph has only polynomially (in the number $n$ of vertices) different minimum cuts. Is this also true for directed graphs? Prove it or give a counterexample."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any undirected graph $G$ can be mapped to a set of directed graphs by assinging a direction to each of edges. This means that for each undirected graph with $e$ edges there are $2^e$ directed graphs that correspond to this one undirected graph.\n",
    "\n",
    "Likewise, for each of the $\\binom{n}{2}$ different minimum cuts of undireced graphs, we can assign a direction to each of the edges that connect the two minimum cuts. These new minimum cuts created by assigning a direction to the edge will only be distinct if the relative direction of the directed egdes are different. This means that for any particular minium cut with $E$ undirected edges connecting the two sets, there are $2^{E-1}$ such arrangements.\n",
    "\n",
    "However, since the number fo edges connected minimum cuts is constant and not dependant upon $n$, the number of differet minimum cuts is still polynomial in n, namely,\n",
    "$$\n",
    "2^{E-1} \\times \\binom{n}{2} = O(n^2)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "For a parameter $\\alpha >1$, an $\\alpha$-minimum cut is one for which the number of crossing edges is at most $\\alpha$ times that of a minimum cut. How many $\\alpha$-minimum cuts can an undirected graph have, as a function of $\\alpha$ and the number $n$ of vertices? Prove the best upper bound that you can."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to stop the contraction algorithm early. Let's say we run the contraction algorithm until there are $r$ supernodes left. \n",
    "Then following the normal derivation, the probability of a particular $\\alpha$-minimum cut surviving is\n",
    "$$\n",
    "p(success) \\geq \\prod_{i=0}^{n-r-1}{\\left(1 - \\frac{2\\alpha}{n - i}\\right)} = \\prod_{i=0}^{n-r-1}{\\left(\\frac{n - 2\\alpha - i}{n - i}\\right)} \\\\[10pt]\n",
    "= \\left(\\frac{n - 2\\alpha}{n}\\right) \\times \\left(\\frac{n - 2\\alpha - 1}{n - 1}\\right) \\times \\cdots \\times \\left(\\frac{r + 1 - 2\\alpha}{r + 1}\\right) \\\\[10pt]\n",
    "= \\frac{(n - 2\\alpha)!}{(r - 2\\alpha)!} \\times \\frac{r!}{n!}\n",
    "$$\n",
    "\n",
    "From looking at the terms in the denominator, a reasonable place to stop the algorithm early is when $r = 2\\alpha$. This makes sure that the probabilty is strictly positive. \n",
    "\n",
    "Lets consider a particular $\\alpha$-minimum cut. Out of these $r$ supervertices there are \n",
    "$$\n",
    "\\frac{2^r - 2}{2}\n",
    "$$\n",
    "non-empty cuts. Where $2^r$ is the number of different ways to assign each node to a left / right set, and we subtract two to remove the two cases where one set is empty, and we divide by two to remove symmertical configurations.\n",
    "\n",
    "Then the probabiltiy of randomly picking an $\\alpha$-minimum is \n",
    "$$\n",
    "\\frac{2}{2^r -2}\n",
    "$$\n",
    "\n",
    "So the probability that the contraction algorithm correctly identifies an $\\alpha$-minimum is\n",
    "$$\n",
    "\\frac{2}{2^r -2} \\times \\frac{(n - 2\\alpha)!}{(r - 2\\alpha)!} \\times \\frac{r!}{n!} = 2 \\times \\frac{r!}{2^r - 2} \\times \\frac{(n - 2\\alpha)!}{n!} \\times \\frac{1}{(r - 2\\alpha)!}\n",
    "$$\n",
    "\n",
    "We consider the following inequalities,\n",
    "$$\n",
    "\\frac{r!}{2^r -2} \\geq 1 \\quad \\text{for} \\quad r \\geq 2 \\\\[10pt]\n",
    "\\frac{(n - 2\\alpha)!}{n!} = \\frac{1}{n \\times (n -1) \\times \\cdots \\times (n - 2\\alpha +1)} > \\frac{1}{n^{2\\alpha}} \\quad \\text{for} \\quad 1 \\leq \\alpha \\leq \\frac{n}{2}\n",
    "$$\n",
    "\n",
    "To get a lower bound for the probabiltiy,\n",
    "$$\n",
    "p(success) \\geq 2 \\times 1 \\times \\frac{1}{n^{2\\alpha}} \\times \\frac{1}{0!} = \\frac{2}{n^{2\\alpha}}\n",
    "$$\n",
    "\n",
    "This gives an upperbound for the maximum number of $\\alpha$-minimum cuts or\n",
    "$$\n",
    "\\frac{n^{2\\alpha}}{2}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 4\n",
    "\n",
    "The file contains the adjacency list representation of a simple undirected graph. There are 200 vertices labeled 1 to 200. The first column in the file represents the vertex label, and the particular row (other entries except the first column) tells all the vertices that the vertex is adjacent to. So for example, the $6^{th}$ row looks like : \"6\t155\t56\t52\t120\t......\". This just means that the vertex with label 6 is adjacent to (i.e., shares an edge with) the vertices with labels 155,56,52,120,......,etc\n",
    "\n",
    "Your task is to code up and run the randomized contraction algorithm for the min cut problem and use it on the above graph to compute the min cut.  (HINT: Note that you'll have to figure out an implementation of edge contractions.  Initially, you might want to do this naively, creating a new graph from the old every time there's an edge contraction.  But you should also think about more efficient implementations.)   (WARNING: As per the video lectures, please make sure to run the algorithm many times with different random seeds, and remember the smallest cut that you ever find.)  Write your numeric answer in the space provided.  So e.g., if your answer is 5, just type 5 in the space provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pformat\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id: list[int]):\n",
    "        self.id = tuple(id)\n",
    "        self.edges: list['Edge'] = []  # list of pointers to edges \n",
    "        return\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.id)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Node):\n",
    "            return False\n",
    "        return self.id == other.id      \n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.edges)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Node{[x for x in self.id]}'\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, connects: list[Node]):\n",
    "        self.connects = frozenset(connects)\n",
    "        return\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.connects)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Edge):\n",
    "            return False\n",
    "        return self.connects == other.connects\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.connects)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Edge{[x for x in self.connects]}'\n",
    "\n",
    "    def bind(self):\n",
    "        for node in self:\n",
    "            node.edges.append(self)\n",
    "        return\n",
    "    \n",
    "    def unbind(self):\n",
    "        for node in self:\n",
    "            node.edges.remove(self)\n",
    "        return\n",
    "\n",
    "class Graph:\n",
    "    '''\n",
    "    Memory usage O(n + e) where there are n nodes and e edges \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.edges = [] # edges can be parallel\n",
    "        self.nodes: dict[tuple[int], Node] = dict() # nodes are singletons referenced by ids\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Graph containing: \\nNodes:\\n{pformat(self.nodes)}\\nEdges:\\n{pformat(self.edges)}'\n",
    "    \n",
    "    '''\n",
    "    Node creation can occur in O(1) time\n",
    "    '''\n",
    "    def add_node(self, node_id: int):\n",
    "        node_key = tuple([node_id])\n",
    "\n",
    "        if node_key in self.nodes:\n",
    "            return self.nodes[node_key]\n",
    "        else:\n",
    "            node = Node([node_id])\n",
    "            self.nodes[node.id] = node\n",
    "            return node\n",
    "    \n",
    "    '''\n",
    "    Node removal occurs in O(k) time, where k is the number of edges the node has\n",
    "    '''\n",
    "    def remove_node(self, node_key: tuple[int]):\n",
    "        node = self.nodes.pop(node_key)\n",
    "        rm_edges = [edge for edge in node]\n",
    "\n",
    "        for edge in rm_edges:\n",
    "            edge.unbind()\n",
    "            if edge in self.edges: self.edges.remove(edge)\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    def add_edge(self, nodes: list[Node], parallel=False):\n",
    "        if len(nodes) == 0:\n",
    "            return\n",
    "\n",
    "        new_edge = Edge(nodes)\n",
    "        if not parallel and (new_edge in nodes[0]):\n",
    "            return\n",
    "        \n",
    "        new_edge.bind()\n",
    "        self.edges.append(new_edge)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    '''\n",
    "    Edge contraction runs in O(k) time where k is the number of edges a node has\n",
    "    '''\n",
    "    def contract_edge(self, edge: Edge):\n",
    "        supernode = Node([id for node in edge for id in node.id])\n",
    "        \n",
    "        for node in edge:\n",
    "            for sub_edge in node:\n",
    "                # this loop filters out self nodes\n",
    "                dest_nodes = [sub_node for sub_node in sub_edge if sub_node not in edge]\n",
    "                if len(dest_nodes) > 0: self.add_edge([supernode, *dest_nodes], parallel=True)\n",
    "            \n",
    "            self.remove_node(node.id)\n",
    "\n",
    "        self.nodes[supernode.id] = supernode\n",
    "        return\n",
    "\n",
    "def load_data_oo(iter: list[int]):\n",
    "    graph = Graph()\n",
    "\n",
    "    for id_list in iter:\n",
    "        new_node_id = int(id_list[0])\n",
    "        node1 = graph.add_node(new_node_id)\n",
    "\n",
    "        for neighbour in id_list[1:]:\n",
    "            adj_node_id = int(neighbour)\n",
    "            node2 = graph.add_node(adj_node_id)\n",
    "\n",
    "            graph.add_edge([node1, node2])\n",
    "\n",
    "    return graph\n",
    "\n",
    "def transform_text():\n",
    "    with open('Week 4 kargerMinCut.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            yield [int(x) for x in line.split('\\t')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    graph = load_data_oo([\n",
    "        [1, 2, 3, 4],\n",
    "        [2, 1, 3, 4],\n",
    "        [3, 1, 2, 4],\n",
    "        [4, 1, 3, 2]\n",
    "    ])\n",
    "\n",
    "    print('*** test case ***')\n",
    "    print(graph)\n",
    "\n",
    "    while len(graph.nodes.keys()) > 2:\n",
    "\n",
    "        testedge = input('Choose an edge to remove: ')\n",
    "        if testedge == \"\" or testedge == \"exit\":\n",
    "            print(\"*** exit ***\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            edge_idx = int(testedge)\n",
    "        except Exception:\n",
    "            print(\"invalid index\")\n",
    "        \n",
    "        c_edge = graph.edges[edge_idx]\n",
    "        print(f'removing edge: {c_edge}')\n",
    "        graph.contract_edge(c_edge)\n",
    "        print(graph)\n",
    "        \n",
    "    else:\n",
    "        print(f'exited with {len(graph.edges)} edges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_data_oo(transform_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2517"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract(graph: Graph):\n",
    "    while len(graph.nodes.keys()) > 2:\n",
    "        random_edge = random.sample(graph.edges, 1)[0]\n",
    "        graph.contract_edge(random_edge)\n",
    "        \n",
    "    else:\n",
    "        print(f'exited with {len(graph.edges)} edges')\n",
    "\n",
    "    return len(graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cut = min([contract(load_data_oo(transform_text())) for r in range(10)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above runs painfully slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DictGraph:\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.edges: list[Tuple[tuple[int], tuple[int]]] = []\n",
    "        self.dict: dict[tuple[int], list[tuple[int]]] = dict()\n",
    "        \n",
    "        for id_list in data:\n",
    "            new_node_id = int(id_list[0])\n",
    "            head_node = self.add_node([new_node_id])\n",
    "\n",
    "            for neighbour in id_list[1:]:\n",
    "                adj_node_id = int(neighbour)\n",
    "                adj_node = self.add_node([adj_node_id])\n",
    "                \n",
    "                self.add_edge(head_node, adj_node)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Graph:\\n{pformat(self.dict)}\\nEdges:\\n{self.edges}'\n",
    "    \n",
    "    def add_node(self, node_id: list[int]):\n",
    "        key = tuple(node_id)\n",
    "        if key not in self.dict:\n",
    "            self.dict[key] = []\n",
    "        return key\n",
    "    \n",
    "    def remove_node(self, node_key: tuple[int]):\n",
    "        adj_nodes = self.dict.pop(node_key)\n",
    "        for node in adj_nodes:\n",
    "            self.dict[node].remove(node_key)\n",
    "\n",
    "    def add_edge(self, node1: tuple[int], node2: tuple[int], parallel=False):\n",
    "        \n",
    "        if not parallel and node2 in self.dict[node1]:\n",
    "            return\n",
    "\n",
    "        self.dict[node1].append(node2)\n",
    "        self.dict[node2].append(node1)   \n",
    "\n",
    "        edge = [node1, node2]\n",
    "        edge.sort()\n",
    "\n",
    "        self.edges.append(tuple(edge))\n",
    "        return\n",
    "    \n",
    "    def remove_edge(self, node1: tuple[int], node2: tuple[int]):\n",
    "        node_list = [node1, node2]\n",
    "        node_list.sort()\n",
    "\n",
    "        edge = tuple(node_list)\n",
    "\n",
    "        if edge in self.edges: self.edges.remove(edge)\n",
    "        return\n",
    "    \n",
    "    def contract_edge(self, edge: Tuple[tuple[int], tuple[int]]):\n",
    "        self.edges.remove(edge)\n",
    "\n",
    "        node1_key, node2_key = edge\n",
    "\n",
    "        supernode_key = self.add_node([*node1_key, *node2_key])\n",
    "\n",
    "        node1_adj = self.dict.pop(node1_key)\n",
    "        node2_adj = self.dict.pop(node2_key)\n",
    "        \n",
    "        for adj_node in node1_adj:\n",
    "            self.remove_edge(adj_node, node1_key)\n",
    "\n",
    "            if adj_node == node2_key: continue\n",
    "            self.dict[adj_node].remove(node1_key)\n",
    "            \n",
    "            self.add_edge(supernode_key, adj_node, parallel=True)\n",
    "\n",
    "        for adj_node in node2_adj:\n",
    "            self.remove_edge(adj_node, node2_key)\n",
    "\n",
    "            if adj_node == node1_key: continue\n",
    "            self.dict[adj_node].remove(node2_key)\n",
    "            \n",
    "            self.add_edge(supernode_key, adj_node, parallel=True)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = DictGraph(transform_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dict():\n",
    "    graph = DictGraph([\n",
    "        [1, 2, 3, 4],\n",
    "        [2, 1, 3, 4],\n",
    "        [3, 1, 2, 4],\n",
    "        [4, 1, 3, 2]\n",
    "    ])\n",
    "\n",
    "    print('*** test case ***')\n",
    "    print(graph)\n",
    "    \n",
    "    while len(graph.dict.keys()) > 2:\n",
    "\n",
    "        testedge = input('Choose an edge to remove: ')\n",
    "        if testedge == \"\" or testedge == \"exit\":\n",
    "            print(\"*** exit ***\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            edge_idx = int(testedge)\n",
    "        except Exception:\n",
    "            print(\"invalid index\")\n",
    "        \n",
    "        c_edge = graph.edges[edge_idx]\n",
    "        print(f'removing edge: {c_edge}')\n",
    "        graph.contract_edge(c_edge)\n",
    "        print(graph)\n",
    "        \n",
    "    else:\n",
    "        print(f'exited with {len(graph.edges)} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** test case ***\n",
      "Graph:\n",
      "{(1,): [(2,), (3,), (4,)],\n",
      " (2,): [(1,), (3,), (4,)],\n",
      " (3,): [(1,), (2,), (4,)],\n",
      " (4,): [(1,), (2,), (3,)]}\n",
      "Edges:\n",
      "[((1,), (2,)), ((1,), (3,)), ((1,), (4,)), ((2,), (3,)), ((2,), (4,)), ((3,), (4,))]\n",
      "removing edge: ((1,), (2,))\n",
      "Graph:\n",
      "{(1, 2): [(3,), (4,), (3,), (4,)],\n",
      " (3,): [(4,), (1, 2), (1, 2)],\n",
      " (4,): [(3,), (1, 2), (1, 2)]}\n",
      "Edges:\n",
      "[((3,), (4,)), ((1, 2), (3,)), ((1, 2), (4,)), ((1, 2), (3,)), ((1, 2), (4,))]\n",
      "removing edge: ((1, 2), (3,))\n",
      "Graph:\n",
      "{(1, 2, 3): [(4,), (4,), (4,)], (4,): [(1, 2, 3), (1, 2, 3), (1, 2, 3)]}\n",
      "Edges:\n",
      "[((1, 2, 3), (4,)), ((1, 2, 3), (4,)), ((1, 2, 3), (4,))]\n",
      "exited with 3 edges\n"
     ]
    }
   ],
   "source": [
    "test_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exited with 21 edges\n",
      "exited with 33 edges\n",
      "exited with 22 edges\n",
      "exited with 24 edges\n",
      "exited with 20 edges\n",
      "exited with 30 edges\n",
      "exited with 22 edges\n",
      "exited with 28 edges\n",
      "exited with 24 edges\n",
      "exited with 20 edges\n",
      "exited with 20 edges\n",
      "exited with 21 edges\n",
      "exited with 20 edges\n",
      "exited with 23 edges\n",
      "exited with 17 edges\n",
      "exited with 20 edges\n",
      "exited with 21 edges\n",
      "exited with 20 edges\n",
      "exited with 22 edges\n",
      "exited with 22 edges\n",
      "exited with 27 edges\n",
      "exited with 21 edges\n",
      "exited with 24 edges\n",
      "exited with 20 edges\n",
      "exited with 21 edges\n",
      "exited with 21 edges\n",
      "exited with 17 edges\n",
      "exited with 17 edges\n",
      "exited with 20 edges\n",
      "exited with 21 edges\n",
      "exited with 22 edges\n",
      "exited with 24 edges\n",
      "exited with 27 edges\n",
      "exited with 21 edges\n",
      "exited with 20 edges\n",
      "exited with 20 edges\n",
      "exited with 26 edges\n",
      "exited with 25 edges\n",
      "exited with 26 edges\n",
      "exited with 46 edges\n",
      "exited with 24 edges\n",
      "exited with 17 edges\n",
      "exited with 20 edges\n",
      "exited with 22 edges\n",
      "exited with 31 edges\n",
      "exited with 25 edges\n",
      "exited with 22 edges\n",
      "exited with 20 edges\n",
      "exited with 24 edges\n",
      "exited with 23 edges\n"
     ]
    }
   ],
   "source": [
    "def contract(graph: Graph):\n",
    "    while len(graph.dict.keys()) > 2:\n",
    "        random_edge = random.sample(graph.edges, 1)[0]\n",
    "        graph.contract_edge(random_edge)\n",
    "    else:\n",
    "        print(f'exited with {len(graph.edges)} edges')\n",
    "\n",
    "    return len(graph.edges)\n",
    "\n",
    "m_cut = min([contract(DictGraph(transform_text())) for r in range(50)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
